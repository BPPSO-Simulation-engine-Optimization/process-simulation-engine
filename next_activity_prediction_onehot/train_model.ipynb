{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Next Activity Prediction Model Training (One-Hot Encoding)\n",
        "\n",
        "This notebook demonstrates how to train an LSTM model for next activity prediction using one-hot encoding.\n",
        "\n",
        "The model:\n",
        "- Filters event logs to only \"start\" and \"complete\" lifecycle transitions\n",
        "- Uses one-hot encoding instead of embedding vectors\n",
        "- Learns to predict the next activity in a case\n",
        "- Detects when a case should end (END token prediction)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Repos\\process-simulation-engine-1\\.venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, \"object\"):\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import logging\n",
        "\n",
        "# Add project root to Python path\n",
        "project_root = Path.cwd().parent if Path.cwd().name == 'next_activity_prediction_onehot' else Path.cwd()\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "from next_activity_prediction_onehot import NextActivityConfigOneHot, train_model_onehot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration\n",
        "\n",
        "Configure the model architecture and training parameters.\n",
        "\n",
        "**Note**: This module uses one-hot encoding, so there is no `embedding_dim` parameter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration:\n",
            "  Event log: ..\\eventlog\\eventlog.xes.gz\n",
            "  Model directory: models\\next_activity_lstm_onehot\n",
            "  Sequence length: 50\n",
            "  LSTM units: 256\n",
            "  LSTM layers: 2\n",
            "  Batch size: 64\n",
            "  Epochs: 1\n",
            "\n",
            "Class weighting:\n",
            "  Enabled: True\n",
            "  Method: balanced\n",
            "  END token weight: auto\n",
            "  Position weights: False (power=1.5)\n",
            "\n",
            "Note: Using one-hot encoding (no embedding layer)\n"
          ]
        }
      ],
      "source": [
        "# Path to your event log\n",
        "EVENT_LOG_PATH = r\"..\\eventlog\\eventlog.xes.gz\"  # Update this to your event log path\n",
        "\n",
        "# Model configuration\n",
        "config = NextActivityConfigOneHot(\n",
        "    # Model architecture\n",
        "    sequence_length=50,      # Maximum sequence length for padding/truncation\n",
        "    lstm_units=256,          # Number of LSTM units per layer\n",
        "    lstm_layers=2,           # Number of stacked LSTM layers\n",
        "    dropout_rate=0.1,        # Dropout rate for regularization\n",
        "    \n",
        "    # Training parameters\n",
        "    batch_size=64,           # Batch size for training\n",
        "    learning_rate=0.001,     # Initial learning rate\n",
        "    epochs=1,               # Maximum number of training epochs\n",
        "    validation_split=0.1,    # Fraction of data for validation\n",
        "    early_stopping_patience=10,  # Early stopping patience\n",
        "    \n",
        "    # Paths\n",
        "    model_dir=\"models/next_activity_lstm_onehot\",  # Where to save the model\n",
        "    event_log_path=EVENT_LOG_PATH,\n",
        "    \n",
        "    # Data preprocessing\n",
        "    min_case_length=2,       # Minimum case length to include\n",
        "    max_case_length=200,     # Maximum case length (longer cases are truncated)\n",
        "    \n",
        "    # Class weighting (to better fit END token distribution)\n",
        "    use_class_weights=True,  # Enable class weighting for imbalanced classes\n",
        "    class_weight_method=\"balanced\",  # \"balanced\" (sklearn style), \"inverse_freq\", or \"custom\"\n",
        "    end_token_weight=None,   # Manual weight for END token (None = auto-calculate based on method)\n",
        "    \n",
        "    # Position-based sample weighting (optional - emphasizes later positions more likely to be END)\n",
        "    use_position_weights=False,  # Set to True to enable position-based weighting\n",
        "    position_weight_power=1.5,   # Power for position weighting (higher = more emphasis on later positions)\n",
        ")\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Event log: {config.event_log_path}\")\n",
        "print(f\"  Model directory: {config.model_dir}\")\n",
        "print(f\"  Sequence length: {config.sequence_length}\")\n",
        "print(f\"  LSTM units: {config.lstm_units}\")\n",
        "print(f\"  LSTM layers: {config.lstm_layers}\")\n",
        "print(f\"  Batch size: {config.batch_size}\")\n",
        "print(f\"  Epochs: {config.epochs}\")\n",
        "print(f\"\\nClass weighting:\")\n",
        "print(f\"  Enabled: {config.use_class_weights}\")\n",
        "print(f\"  Method: {config.class_weight_method}\")\n",
        "print(f\"  END token weight: {config.end_token_weight if config.end_token_weight else 'auto'}\")\n",
        "print(f\"  Position weights: {config.use_position_weights} (power={config.position_weight_power})\")\n",
        "print(f\"\\nNote: Using one-hot encoding (no embedding layer)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Verify Event Log\n",
        "\n",
        "Check that the event log exists and has the required columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Repos\\process-simulation-engine-1\\.venv\\Lib\\site-packages\\pm4py\\utils.py:987: UserWarning: In the current version, the import/export operation uses `rustxes` by default for importing/exporting files faster. Please uninstall `rustxes` to revert the behavior.\n",
            "  warnings.warn(\"In the current version, the import/export operation uses `rustxes` by default for importing/exporting files faster. Please uninstall `rustxes` to revert the behavior.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Event log loaded: 1202267 events, 31509 cases\n",
            "\n",
            "Columns: ['concept:name', 'time:timestamp', 'NumberOfTerms', 'org:resource', 'Action', 'FirstWithdrawalAmount', 'MonthlyCost', 'OfferID', 'EventID', 'CreditScore', 'case:ApplicationType', 'Selected', 'lifecycle:transition', 'case:concept:name', 'case:RequestedAmount', 'Accepted', 'OfferedAmount', 'EventOrigin', 'case:LoanGoal']\n",
            "\n",
            "Lifecycle transitions:\n",
            "lifecycle:transition\n",
            "complete     475306\n",
            "suspend      215402\n",
            "schedule     149104\n",
            "start        128227\n",
            "resume       127160\n",
            "ate_abort     85224\n",
            "withdraw      21844\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Start/Complete events: 603533 (50.2%)\n",
            "\n",
            "Unique activities: 26\n",
            "Sample activities: ['A_Create Application', 'A_Submitted', 'W_Handle leads', 'W_Complete application', 'A_Concept', 'A_Accepted', 'O_Create Offer', 'O_Created', 'O_Sent (mail and online)', 'W_Call after offers']\n",
            "\n",
            "Note: One-hot encoding will create vectors of size 28 (activities + PAD + END)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pm4py\n",
        "\n",
        "# Load and inspect event log\n",
        "if Path(EVENT_LOG_PATH).exists():\n",
        "    log = pm4py.read_xes(EVENT_LOG_PATH)\n",
        "    df = pm4py.convert_to_dataframe(log)\n",
        "    \n",
        "    print(f\"Event log loaded: {len(df)} events, {df['case:concept:name'].nunique()} cases\")\n",
        "    print(f\"\\nColumns: {list(df.columns)}\")\n",
        "    \n",
        "    # Check for lifecycle column\n",
        "    if 'lifecycle:transition' in df.columns:\n",
        "        lifecycle_counts = df['lifecycle:transition'].value_counts()\n",
        "        print(f\"\\nLifecycle transitions:\")\n",
        "        print(lifecycle_counts)\n",
        "        \n",
        "        start_complete = df[df['lifecycle:transition'].isin(['start', 'complete'])]\n",
        "        print(f\"\\nStart/Complete events: {len(start_complete)} ({len(start_complete)/len(df):.1%})\")\n",
        "    else:\n",
        "        print(\"\\nWarning: No 'lifecycle:transition' column found\")\n",
        "    \n",
        "    # Show sample activities\n",
        "    if 'concept:name' in df.columns:\n",
        "        activities = df['concept:name'].unique()\n",
        "        print(f\"\\nUnique activities: {len(activities)}\")\n",
        "        print(f\"Sample activities: {list(activities[:10])}\")\n",
        "        print(f\"\\nNote: One-hot encoding will create vectors of size {len(activities) + 2} (activities + PAD + END)\")\n",
        "else:\n",
        "    print(f\"Event log not found: {EVENT_LOG_PATH}\")\n",
        "    print(\"Please update EVENT_LOG_PATH in the configuration cell above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train the Model\n",
        "\n",
        "Train the LSTM model on the event log. This will:\n",
        "1. Load and preprocess the event log\n",
        "2. Filter to start/complete lifecycles\n",
        "3. Extract activity sequences\n",
        "4. Convert to one-hot encoded format\n",
        "5. Create training/validation splits\n",
        "6. Train the model with early stopping\n",
        "7. Save the trained model and metadata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-09 16:23:34,675 - next_activity_prediction_onehot.trainer - INFO - Starting model training with one-hot encoding...\n",
            "2026-01-09 16:23:34,676 - next_activity_prediction_onehot.trainer - INFO - Event log: ..\\eventlog\\eventlog.xes.gz\n",
            "2026-01-09 16:23:34,677 - next_activity_prediction_onehot.trainer - INFO - Model directory: models\\next_activity_lstm_onehot\n",
            "2026-01-09 16:23:34,677 - next_activity_prediction_onehot.data_preprocessing - INFO - Loading event log from ..\\eventlog\\eventlog.xes.gz\n",
            "2026-01-09 16:23:46,394 - next_activity_prediction_onehot.data_preprocessing - INFO - Loaded 1202267 events, 31509 cases\n",
            "2026-01-09 16:23:46,637 - next_activity_prediction_onehot.data_preprocessing - INFO - Filtered to start/complete lifecycles: 1,202,267 -> 603,533 (50.2%)\n",
            "2026-01-09 16:23:48,744 - next_activity_prediction_onehot.data_preprocessing - INFO - Extracted 31509 case sequences\n",
            "2026-01-09 16:23:48,747 - next_activity_prediction_onehot.data_preprocessing - INFO - Average sequence length: 20.2 (including END)\n",
            "2026-01-09 16:23:48,751 - next_activity_prediction_onehot.data_preprocessing - INFO - Min/Max sequence length: 9/68\n",
            "2026-01-09 16:23:48,850 - next_activity_prediction_onehot.data_preprocessing - INFO - Created vocabulary with 28 activities (including END)\n",
            "2026-01-09 16:23:48,850 - next_activity_prediction_onehot.data_preprocessing - INFO - END token index: 27\n",
            "2026-01-09 16:23:48,851 - next_activity_prediction_onehot.trainer - INFO - Vocabulary size: 28 (including END token)\n",
            "2026-01-09 16:24:06,340 - next_activity_prediction_onehot.data_preprocessing - INFO - Prepared 603533 training samples\n",
            "2026-01-09 16:24:06,341 - next_activity_prediction_onehot.data_preprocessing - INFO - Input shape: (603533, 50, 28) (samples, sequence_length, vocab_size)\n",
            "2026-01-09 16:24:06,341 - next_activity_prediction_onehot.data_preprocessing - INFO - END token count: 31509 (5.22%)\n",
            "2026-01-09 16:24:11,169 - next_activity_prediction_onehot.trainer - INFO - Train samples: 543179, Validation samples: 60354\n",
            "2026-01-09 16:24:11,224 - next_activity_prediction_onehot.trainer - INFO - Input shape: (543179, 50, 28) (samples, sequence_length, vocab_size)\n",
            "2026-01-09 16:24:12,046 - next_activity_prediction_onehot.trainer - INFO - Model architecture:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"next_activity_lstm_onehot\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"next_activity_lstm_onehot\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ sequence_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">291,840</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ final_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activity_prediction (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,196</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ sequence_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m28\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m291,840\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m525,312\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ final_dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activity_prediction (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │         \u001b[38;5;34m7,196\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">824,348</span> (3.14 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m824,348\u001b[0m (3.14 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">824,348</span> (3.14 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m824,348\u001b[0m (3.14 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-09 16:24:12,189 - next_activity_prediction_onehot.utils - INFO - Class weights (method=balanced):\n",
            "2026-01-09 16:24:12,191 - next_activity_prediction_onehot.utils - INFO -   END token (idx=27): count=28411, weight=0.735\n",
            "2026-01-09 16:24:12,191 - next_activity_prediction_onehot.utils - INFO -   Min weight: 0.419, Max weight: 6963.833\n",
            "2026-01-09 16:24:12,192 - next_activity_prediction_onehot.utils - INFO -   Average weight: 262.591\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7917/8488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1:02\u001b[0m 110ms/step - loss: 1.4208 - sparse_categorical_accuracy: 0.6170"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = train_model_onehot(config)\n",
        "\n",
        "print(\"\\nTraining completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training Results\n",
        "\n",
        "Visualize training progress and metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training history\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Loss\n",
        "axes[0].plot(history['loss'], label='Train Loss')\n",
        "axes[0].plot(history['val_loss'], label='Val Loss')\n",
        "axes[0].set_title('Model Loss')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True)\n",
        "\n",
        "# Accuracy\n",
        "axes[1].plot(history['sparse_categorical_accuracy'], label='Train Accuracy')\n",
        "axes[1].plot(history['val_sparse_categorical_accuracy'], label='Val Accuracy')\n",
        "axes[1].set_title('Activity Prediction Accuracy')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print final metrics\n",
        "print(\"Final Training Metrics:\")\n",
        "print(f\"  Loss: {history['loss'][-1]:.4f}\")\n",
        "print(f\"  Accuracy: {history['sparse_categorical_accuracy'][-1]:.4f}\")\n",
        "print(f\"\\nFinal Validation Metrics:\")\n",
        "print(f\"  Loss: {history['val_loss'][-1]:.4f}\")\n",
        "print(f\"  Accuracy: {history['val_sparse_categorical_accuracy'][-1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Verify Model Files\n",
        "\n",
        "Check that the model and metadata were saved correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dir = Path(config.model_dir)\n",
        "\n",
        "print(f\"Model directory: {model_dir}\")\n",
        "print(f\"\\nFiles in model directory:\")\n",
        "if model_dir.exists():\n",
        "    for file in sorted(model_dir.rglob('*')):\n",
        "        if file.is_file():\n",
        "            size = file.stat().st_size / (1024 * 1024)  # Size in MB\n",
        "            print(f\"  {file.relative_to(model_dir)} ({size:.2f} MB)\")\n",
        "    \n",
        "    # Load and display metadata\n",
        "    metadata_file = model_dir / \"metadata.json\"\n",
        "    if metadata_file.exists():\n",
        "        import json\n",
        "        with open(metadata_file, 'r') as f:\n",
        "            metadata = json.load(f)\n",
        "        \n",
        "        print(f\"\\nModel Metadata:\")\n",
        "        print(f\"  Vocabulary size: {metadata.get('vocab_size', 'N/A')}\")\n",
        "        print(f\"  Sequence length: {metadata.get('sequence_length', 'N/A')}\")\n",
        "        print(f\"  LSTM units: {metadata.get('lstm_units', 'N/A')}\")\n",
        "        print(f\"  LSTM layers: {metadata.get('lstm_layers', 'N/A')}\")\n",
        "        print(f\"  END token index: {metadata.get('end_token_idx', 'N/A')}\")\n",
        "        print(f\"  Input shape: (sequence_length, vocab_size) = ({metadata.get('sequence_length', 'N/A')}, {metadata.get('vocab_size', 'N/A')})\")\n",
        "        \n",
        "        vocab_size = metadata.get('vocab_size', 0)\n",
        "        print(f\"\\nVocabulary (first 20 activities):\")\n",
        "        idx_to_activity = metadata.get('idx_to_activity', {})\n",
        "        for idx in sorted([int(k) for k in idx_to_activity.keys()])[:20]:\n",
        "            if idx != 0:  # Skip PAD token\n",
        "                print(f\"  {idx}: {idx_to_activity[str(idx)]}\")\n",
        "else:\n",
        "    print(\"Model directory does not exist.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from next_activity_prediction_onehot import LSTMNextActivityPredictorOneHot\n",
        "from simulation.case_manager import CaseState\n",
        "\n",
        "# Load the predictor\n",
        "predictor = LSTMNextActivityPredictorOneHot(\n",
        "    model_path=str(config.model_dir)\n",
        ")\n",
        "\n",
        "print(\"Predictor loaded successfully!\")\n",
        "print(f\"Vocabulary size: {len(predictor.activity_to_idx)} (including END)\")\n",
        "print(f\"Sequence length: {predictor.sequence_length}\")\n",
        "print(f\"END token index: {predictor.end_token_idx}\")\n",
        "print(f\"Input shape: (sequence_length, vocab_size) = ({predictor.sequence_length}, {predictor.vocab_size})\")\n",
        "\n",
        "# Create a test case\n",
        "test_case = CaseState(\n",
        "    case_id=\"test_case_1\",\n",
        "    case_type=\"Home improvement\",\n",
        "    application_type=\"New credit\",\n",
        "    requested_amount=10000.0\n",
        ")\n",
        "\n",
        "# Simulate a case progression\n",
        "test_activities = [\n",
        "    \"A_Create Application\",\n",
        "    \"A_Submitted\",\n",
        "    \"W_Complete application\"\n",
        "]\n",
        "\n",
        "print(\"\\nTesting predictions:\")\n",
        "for i, activity in enumerate(test_activities):\n",
        "    test_case.activity_history = test_activities[:i+1]\n",
        "    next_activity, is_end = predictor.predict(test_case)\n",
        "    \n",
        "    print(f\"\\nStep {i+1}:\")\n",
        "    print(f\"  History: {test_case.activity_history}\")\n",
        "    print(f\"  Predicted next: {next_activity}\")\n",
        "    print(f\"  Is END: {is_end}\")\n",
        "    \n",
        "    if is_end:\n",
        "        print(\"  Case ended!\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Next Steps\n",
        "\n",
        "The trained model is now ready to use in simulation:\n",
        "\n",
        "1. **Automatic Integration**: The simulation engine can load this model if configured appropriately\n",
        "\n",
        "2. **Manual Usage**: You can explicitly create a predictor:\n",
        "   ```python\n",
        "   from next_activity_prediction_onehot import LSTMNextActivityPredictorOneHot\n",
        "   predictor = LSTMNextActivityPredictorOneHot(model_path=\"models/next_activity_lstm_onehot\")\n",
        "   ```\n",
        "\n",
        "3. **Run Simulation**: Use the predictor in your simulation runs\n",
        "\n",
        "4. **Compare with Embedding Version**: You can compare performance with the embedding-based module (`next_activity_prediction/`)\n",
        "\n",
        "5. **Tune Parameters**: Adjust the configuration (sequence_length, lstm_units, etc.) and retrain if needed for better performance\n",
        "\n",
        "**Key Differences from Embedding-Based Module:**\n",
        "- Uses one-hot encoding instead of learned embeddings\n",
        "- Input shape is `(sequence_length, vocab_size)` instead of `(sequence_length,)`\n",
        "- No embedding layer parameters\n",
        "- More interpretable but potentially more memory-intensive for large vocabularies\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
