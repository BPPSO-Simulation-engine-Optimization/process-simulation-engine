{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Evaluation\n",
        "\n",
        "Evaluate a trained LSTM model on holdout data with baseline comparison and feature importance analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Repos\\process-simulation-engine\\.venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, \"object\"):\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "from storage import ModelPersistence\n",
        "from evaluation import ModelEvaluator, FeatureImportanceAnalyzer\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODELS_DIR = os.path.join(os.getcwd(), \"..\", \"models_lstm\")\n",
        "DATA_PATH = os.path.join(os.getcwd(), \"..\", \"data\", \"processed\", \"dp_split_datasets_full_simple.joblib\")\n",
        "\n",
        "DECISION_POINT = \"DP 1\"  # Change this to evaluate different decision points\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. List Available Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available models: 43\n",
            "DP 1, DP 3, DP 4, DP 5, DP 7, DP 8, DP 9, DP 10, DP 11, DP 12, DP 13, DP 14, DP 15, DP 16, DP 17, DP 19, DP 20, DP 21, DP 22, DP 23, DP 25, DP 26, DP 27, DP 28, DP 29, DP 30, DP 31, DP 32, DP 33, DP 34, DP 35, DP 36, DP 37, DP 39, DP 40, DP 41, DP 42, DP 43, DP 44, DP 46, DP 47, DP 48, DP 49\n"
          ]
        }
      ],
      "source": [
        "available = [d.replace(\"_\", \" \") for d in os.listdir(MODELS_DIR) if os.path.isdir(os.path.join(MODELS_DIR, d))]\n",
        "print(f\"Available models: {len(available)}\")\n",
        "print(\", \".join(sorted(available, key=lambda x: int(x.split()[1]))))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Model and Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded model for DP 1\n",
            "  Activities: 2\n",
            "  Resources: 112\n",
            "  Classes: ['A_Concept', 'A_Submitted', 'W_Complete application']\n",
            "  Max sequence length: 1\n"
          ]
        }
      ],
      "source": [
        "model_path = os.path.join(MODELS_DIR, DECISION_POINT.replace(\" \", \"_\"))\n",
        "bundle = ModelPersistence.load(model_path)\n",
        "\n",
        "print(f\"Loaded model for {DECISION_POINT}\")\n",
        "print(f\"  Activities: {len(bundle['activity_encoder'].classes_)}\")\n",
        "print(f\"  Resources: {len(bundle['resource_encoder'].classes_)}\")\n",
        "print(f\"  Classes: {list(bundle['label_encoder'].classes_)}\")\n",
        "print(f\"  Max sequence length: {bundle['max_seq_len']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "EOFError",
          "evalue": "Ran out of input",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mEOFError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m splits = \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df_holdout = splits[DECISION_POINT][\u001b[33m\"\u001b[39m\u001b[33mholdout\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHoldout set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_holdout)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m samples\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Repos\\process-simulation-engine\\.venv\\Lib\\site-packages\\joblib\\numpy_pickle.py:749\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode, ensure_native_byte_order)\u001b[39m\n\u001b[32m    744\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[32m    746\u001b[39m             \u001b[38;5;66;03m# A memory-mapped array has to be mapped with the endianness\u001b[39;00m\n\u001b[32m    747\u001b[39m             \u001b[38;5;66;03m# it has been written with. Other arrays are coerced to the\u001b[39;00m\n\u001b[32m    748\u001b[39m             \u001b[38;5;66;03m# native endianness of the host system.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m             obj = \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    750\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[43m                \u001b[49m\u001b[43mensure_native_byte_order\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_native_byte_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    752\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    753\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidated_mmap_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    754\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Repos\\process-simulation-engine\\.venv\\Lib\\site-packages\\joblib\\numpy_pickle.py:626\u001b[39m, in \u001b[36m_unpickle\u001b[39m\u001b[34m(fobj, ensure_native_byte_order, filename, mmap_mode)\u001b[39m\n\u001b[32m    624\u001b[39m obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     obj = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    627\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m unpickler.compat_mode:\n\u001b[32m    628\u001b[39m         warnings.warn(\n\u001b[32m    629\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe file \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m has been generated with a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    630\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mjoblib version less than 0.10. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    633\u001b[39m             stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    634\u001b[39m         )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pickle.py:1205\u001b[39m, in \u001b[36m_Unpickler.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1203\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[32m   1204\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[32m-> \u001b[39m\u001b[32m1205\u001b[39m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[32m   1207\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst.value\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Repos\\process-simulation-engine\\.venv\\Lib\\site-packages\\joblib\\numpy_pickle.py:462\u001b[39m, in \u001b[36mNumpyUnpickler.load_build\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    460\u001b[39m     _array_payload = array_wrapper.read(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m     _array_payload = \u001b[43marray_wrapper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mensure_native_byte_order\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[38;5;28mself\u001b[39m.stack.append(_array_payload)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Repos\\process-simulation-engine\\.venv\\Lib\\site-packages\\joblib\\numpy_pickle.py:284\u001b[39m, in \u001b[36mNumpyArrayWrapper.read\u001b[39m\u001b[34m(self, unpickler, ensure_native_byte_order)\u001b[39m\n\u001b[32m    282\u001b[39m     array = \u001b[38;5;28mself\u001b[39m.read_mmap(unpickler)\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     array = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43munpickler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_native_byte_order\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[38;5;66;03m# Manage array subclass case\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array, \u001b[33m\"\u001b[39m\u001b[33m__array_prepare__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.subclass \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m    288\u001b[39m     unpickler.np.ndarray,\n\u001b[32m    289\u001b[39m     unpickler.np.memmap,\n\u001b[32m    290\u001b[39m ):\n\u001b[32m    291\u001b[39m     \u001b[38;5;66;03m# We need to reconstruct another subclass\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Repos\\process-simulation-engine\\.venv\\Lib\\site-packages\\joblib\\numpy_pickle.py:175\u001b[39m, in \u001b[36mNumpyArrayWrapper.read_array\u001b[39m\u001b[34m(self, unpickler, ensure_native_byte_order)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;66;03m# Now read the actual data.\u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dtype.hasobject:\n\u001b[32m    174\u001b[39m     \u001b[38;5;66;03m# The array contained Python objects. We need to unpickle the data.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     array = \u001b[43mpickle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfile_handle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    177\u001b[39m     numpy_array_alignment_bytes = \u001b[38;5;28mself\u001b[39m.safe_get_numpy_array_alignment_bytes()\n",
            "\u001b[31mEOFError\u001b[39m: Ran out of input"
          ]
        }
      ],
      "source": [
        "splits = joblib.load(DATA_PATH)\n",
        "df_holdout = splits[DECISION_POINT][\"holdout\"]\n",
        "\n",
        "print(f\"Holdout set: {len(df_holdout)} samples\")\n",
        "print(f\"Label distribution:\")\n",
        "print(df_holdout[\"label\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Evaluate Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluator = ModelEvaluator(bundle)\n",
        "X_test, y_test = evaluator.prepare_holdout(df_holdout)\n",
        "\n",
        "report = evaluator.evaluate(X_test, y_test, print_report=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Compare with Baseline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"\\n=== Comparison for {DECISION_POINT} ===\")\n",
        "comparison = evaluator.compare_with_baseline(df_holdout, print_result=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Feature Importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "analyzer = FeatureImportanceAnalyzer(bundle[\"model\"])\n",
        "\n",
        "importances, feature_names, baseline_acc = analyzer.all_features_importance(\n",
        "    X_test, y_test,\n",
        "    context_feature_names=bundle[\"context_keys\"],\n",
        "    n_repeats=3\n",
        ")\n",
        "\n",
        "print(f\"\\nBaseline accuracy: {baseline_acc:.3f}\")\n",
        "print(\"\\nFeature importances:\")\n",
        "for name, imp in sorted(zip(feature_names, importances), key=lambda x: -x[1]):\n",
        "    print(f\"  {name}: {imp:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FeatureImportanceAnalyzer.plot(\n",
        "    feature_names, importances,\n",
        "    title=f\"Feature Importance - {DECISION_POINT}\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Evaluate All Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "for dp in splits.keys():\n",
        "    dp_path = os.path.join(MODELS_DIR, dp.replace(\" \", \"_\"))\n",
        "    if not os.path.exists(dp_path):\n",
        "        continue\n",
        "    \n",
        "    bundle = ModelPersistence.load(dp_path)\n",
        "    df = splits[dp][\"holdout\"]\n",
        "    \n",
        "    if df.empty:\n",
        "        continue\n",
        "    \n",
        "    evaluator = ModelEvaluator(bundle)\n",
        "    comparison = evaluator.compare_with_baseline(df, print_result=False)\n",
        "    \n",
        "    if comparison:\n",
        "        results.append({\n",
        "            \"decision_point\": dp,\n",
        "            \"f1_lstm\": comparison[\"f1_lstm\"],\n",
        "            \"f1_baseline\": comparison[\"f1_baseline\"],\n",
        "            \"improvement\": comparison[\"relative_improvement\"]\n",
        "        })\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results = df_results.sort_values(\"improvement\", ascending=False)\n",
        "\n",
        "print(f\"\\n=== All Models Summary ===\")\n",
        "print(f\"Average F1 (LSTM): {df_results['f1_lstm'].mean():.3f}\")\n",
        "print(f\"Average F1 (Baseline): {df_results['f1_baseline'].mean():.3f}\")\n",
        "print(f\"Average Improvement: {df_results['improvement'].mean():.2f}%\")\n",
        "print(\"\\nTop 5 improved:\")\n",
        "print(df_results.head())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
