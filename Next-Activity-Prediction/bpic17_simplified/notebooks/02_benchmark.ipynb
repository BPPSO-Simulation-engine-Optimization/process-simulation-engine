{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BPIC17 Simplified Model - Benchmarking\n",
        "\n",
        "Run simulation with BPIC17SimplifiedPredictor and compare results with ground truth using SimulationBenchmark.\n",
        "\n",
        "**Workflow:**\n",
        "1. Load trained model\n",
        "2. Run simulation with BPIC17SimplifiedPredictor\n",
        "3. Generate simulated event log\n",
        "4. Compare with ground truth using SimulationBenchmark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Repos\\process-simulation-engine\\.venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, \"object\"):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Benchmarking started: 2026-01-06 23:41:43.880683\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path(__file__).parent.parent.parent.parent if '__file__' in globals() else Path.cwd().parent.parent.parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Add Next-Activity-Prediction to path\n",
        "na_root = project_root / \"Next-Activity-Prediction\"\n",
        "if str(na_root) not in sys.path:\n",
        "    sys.path.insert(0, str(na_root))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from bpic17_simplified import BPIC17SimplifiedPredictor\n",
        "from simulation.engine import DESEngine\n",
        "from simulation.log_exporter import LogExporter\n",
        "from resources import ResourceAllocator\n",
        "from integration.SimulationBenchmark import SimulationBenchmark\n",
        "from processing_time_prediction.ProcessingTimePredictionClass import ProcessingTimePredictionClass\n",
        "\n",
        "# Optional imports with fallback\n",
        "try:\n",
        "    from case_arrival_times_prediction.simulation import ArrivalGenerator\n",
        "    from case_arrival_times_prediction.data_loader import load_daily_sequences\n",
        "except ImportError:\n",
        "    ArrivalGenerator = None\n",
        "    load_daily_sequences = None\n",
        "\n",
        "try:\n",
        "    from case_attributes_prediction.case_attributes import CaseAttributePredictor\n",
        "except ImportError:\n",
        "    CaseAttributePredictor = None\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(f\"Benchmarking started: {datetime.now()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model path: d:\\Repos\\process-simulation-engine\\models\\bpic17_simplified\n",
            "Output directory: d:\\Repos\\process-simulation-engine\\integration\\output\\bpic17_simplified\n",
            "Number of cases: 100\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "MODEL_PATH = os.path.join(project_root, \"models\", \"bpic17_simplified\")\n",
        "EVENT_LOG_PATH = os.path.join(project_root, \"eventlog\", \"eventlog.xes.gz\")\n",
        "OUTPUT_DIR = os.path.join(project_root, \"integration\", \"output\", \"bpic17_simplified\")\n",
        "\n",
        "# Simulation parameters\n",
        "NUM_CASES = 100\n",
        "START_TIME = datetime(2016, 1, 4, 8, 0)  # Monday 8am, Jan 2016\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Model path: {MODEL_PATH}\")\n",
        "print(f\"Output directory: {OUTPUT_DIR}\")\n",
        "print(f\"Number of cases: {NUM_CASES}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Predictors and Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading BPIC17SimplifiedPredictor...\n",
            "WARNING:tensorflow:From d:\\Repos\\process-simulation-engine\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "✓ Next activity predictor loaded\n",
            "\n",
            "Loading ResourceAllocator...\n",
            "[AUTO-LOAD] Found cached model at d:\\Repos\\process-simulation-engine\\resources\\resource_availabilities\\bpic2017_resource_model.pkl\n",
            "            Loading pre-trained model (fast)...\n",
            "[LOADING] Loading model from: d:\\Repos\\process-simulation-engine\\resources\\resource_availabilities\\bpic2017_resource_model.pkl\n",
            "[SUCCESS] Model loaded\n",
            "          - 144 resource patterns\n",
            "          - 141 clustered resources\n",
            "          - 0 busy periods\n",
            "[AUTO-LOAD] Model loaded successfully!\n",
            "✓ Resource allocator loaded\n",
            "\n",
            "Loading ProcessingTimePredictor...\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "Model metadata file not found at models/processing_time_model_metadata.joblib",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✓ Resource allocator loaded\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mLoading ProcessingTimePredictor...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m processing_time_predictor = \u001b[43mProcessingTimePredictionClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✓ Processing time predictor loaded\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mLoading CaseAttributePredictor...\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Repos\\process-simulation-engine\\processing_time_prediction\\ProcessingTimePredictionClass.py:60\u001b[39m, in \u001b[36mProcessingTimePredictionClass.__init__\u001b[39m\u001b[34m(self, method, model_path)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mself\u001b[39m.y_std: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     59\u001b[39m base_path = model_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmodels/processing_time_model\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Repos\\process-simulation-engine\\processing_time_prediction\\ProcessingTimePredictionClass.py:138\u001b[39m, in \u001b[36mProcessingTimePredictionClass.load_model\u001b[39m\u001b[34m(self, filepath)\u001b[39m\n\u001b[32m    135\u001b[39m metadata_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_metadata.joblib\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(metadata_path):\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel metadata file not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetadata_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    140\u001b[39m metadata = joblib.load(metadata_path)\n\u001b[32m    141\u001b[39m \u001b[38;5;28mself\u001b[39m.method = metadata.get(\u001b[33m'\u001b[39m\u001b[33mmethod\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mml\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: Model metadata file not found at models/processing_time_model_metadata.joblib"
          ]
        }
      ],
      "source": [
        "print(\"Loading BPIC17SimplifiedPredictor...\")\n",
        "next_activity_predictor = BPIC17SimplifiedPredictor(model_path=MODEL_PATH)\n",
        "print(\"✓ Next activity predictor loaded\")\n",
        "\n",
        "print(\"\\nLoading ResourceAllocator...\")\n",
        "resource_allocator = ResourceAllocator(log_path=EVENT_LOG_PATH)\n",
        "print(\"✓ Resource allocator loaded\")\n",
        "\n",
        "print(\"\\nLoading ProcessingTimePredictor...\")\n",
        "processing_time_predictor = ProcessingTimePredictionClass()\n",
        "print(\"✓ Processing time predictor loaded\")\n",
        "\n",
        "print(\"\\nLoading CaseAttributePredictor...\")\n",
        "case_attribute_predictor = CaseAttributePredictor()\n",
        "print(\"✓ Case attribute predictor loaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Generate Case Arrivals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Generating case arrivals...\")\n",
        "arrival_generator = ArrivalGenerator(L=24, verbose=False, random_state=42)\n",
        "\n",
        "# Load training data for arrival generation\n",
        "from case_arrival_times_prediction.data_loader import load_daily_sequences\n",
        "daily_sequences = load_daily_sequences(EVENT_LOG_PATH)\n",
        "\n",
        "# Generate arrivals (simplified - you may need to adjust based on your arrival generator setup)\n",
        "# For now, we'll use a simple approach\n",
        "arrival_timestamps = []\n",
        "current_time = START_TIME\n",
        "for i in range(NUM_CASES):\n",
        "    arrival_timestamps.append(current_time)\n",
        "    # Simple inter-arrival: add random time between 1-10 hours\n",
        "    import random\n",
        "    random.seed(42 + i)\n",
        "    hours = random.uniform(1, 10)\n",
        "    current_time = current_time + pd.Timedelta(hours=hours)\n",
        "\n",
        "print(f\"Generated {len(arrival_timestamps)} case arrivals\")\n",
        "print(f\"First arrival: {arrival_timestamps[0]}\")\n",
        "print(f\"Last arrival: {arrival_timestamps[-1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Run Simulation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Initializing simulation engine...\")\n",
        "engine = DESEngine(\n",
        "    resource_allocator=resource_allocator,\n",
        "    arrival_timestamps=arrival_timestamps,\n",
        "    next_activity_predictor=next_activity_predictor,\n",
        "    processing_time_predictor=processing_time_predictor,\n",
        "    case_attribute_predictor=case_attribute_predictor,\n",
        "    start_time=START_TIME,\n",
        ")\n",
        "\n",
        "print(f\"\\nRunning simulation for {NUM_CASES} cases...\")\n",
        "events = engine.run(num_cases=NUM_CASES)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SIMULATION RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"  Cases started: {engine.stats['cases_started']}\")\n",
        "print(f\"  Cases completed: {engine.stats['cases_completed']}\")\n",
        "print(f\"  Events generated: {len(events)}\")\n",
        "print(f\"  Outside hours: {engine.stats['outside_hours_count']}\")\n",
        "print(f\"  No eligible: {engine.stats['no_eligible_failures']}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Export Simulated Log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "simulated_csv = os.path.join(OUTPUT_DIR, \"simulated_log.csv\")\n",
        "simulated_xes = os.path.join(OUTPUT_DIR, \"simulated_log.xes\")\n",
        "\n",
        "print(\"Exporting simulated log...\")\n",
        "LogExporter.to_csv(events, simulated_csv)\n",
        "print(f\"✓ CSV exported to: {simulated_csv}\")\n",
        "\n",
        "try:\n",
        "    LogExporter.to_xes(events, simulated_xes)\n",
        "    print(f\"✓ XES exported to: {simulated_xes}\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠ Could not export XES: {e}\")\n",
        "\n",
        "print(f\"\\nSample events (first 5):\")\n",
        "for e in events[:5]:\n",
        "    ts = e['time:timestamp'].strftime('%Y-%m-%d %H:%M')\n",
        "    print(f\"  [{ts}] {e['case:concept:name']}: {e['concept:name']} (by {e.get('org:resource', 'N/A')})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Load Ground Truth Log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load ground truth from original event log\n",
        "# Filter to same number of cases for fair comparison\n",
        "import pm4py\n",
        "\n",
        "print(\"Loading ground truth event log...\")\n",
        "ground_truth_log = pm4py.read_xes(EVENT_LOG_PATH)\n",
        "df_ground = pm4py.convert_to_dataframe(ground_truth_log)\n",
        "\n",
        "# Filter to start/complete only (matching our model)\n",
        "df_ground = df_ground[df_ground['lifecycle:transition'].isin(['start', 'complete'])].copy()\n",
        "\n",
        "# Sample same number of cases\n",
        "unique_cases = df_ground['case:concept:name'].unique()\n",
        "if len(unique_cases) > NUM_CASES:\n",
        "    sampled_cases = np.random.choice(unique_cases, NUM_CASES, replace=False)\n",
        "    df_ground = df_ground[df_ground['case:concept:name'].isin(sampled_cases)].copy()\n",
        "\n",
        "ground_truth_csv = os.path.join(OUTPUT_DIR, \"ground_truth_log.csv\")\n",
        "df_ground.to_csv(ground_truth_csv, index=False)\n",
        "print(f\"✓ Ground truth exported to: {ground_truth_csv}\")\n",
        "print(f\"  Cases: {df_ground['case:concept:name'].nunique()}\")\n",
        "print(f\"  Events: {len(df_ground)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Run Benchmark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"SIMULATION BENCHMARK\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Ground truth: {ground_truth_csv}\")\n",
        "print(f\"Simulated: {simulated_csv}\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "\n",
        "benchmark = SimulationBenchmark(ground_truth_csv, simulated_csv)\n",
        "\n",
        "print(\"Computing metrics...\")\n",
        "results = benchmark.compute_all_metrics()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "benchmark.print_summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Export Benchmark Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_path = os.path.join(OUTPUT_DIR, \"benchmark_results.xlsx\")\n",
        "print(f\"Exporting results to: {output_path}\")\n",
        "benchmark.export_results(output_path)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"BENCHMARK COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Results saved to: {output_path}\")\n",
        "print(f\"Benchmarking completed at: {datetime.now()}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
