{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BPIC17 Simplified Next Activity Prediction - Training\n",
        "\n",
        "Train a model that predicts both next activity AND lifecycle transition using only start/complete lifecycle transitions and END tokens for trace termination.\n",
        "\n",
        "**Key Features:**\n",
        "- Filters event log to only \"start\" and \"complete\" lifecycle transitions\n",
        "- Adds END tokens at trace endings\n",
        "- Dual output: activity + lifecycle prediction\n",
        "- Optimized for BPIC 2017 event log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training started: 2026-01-06 23:56:00.587959\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path(__file__).parent.parent.parent.parent if '__file__' in globals() else Path.cwd().parent.parent.parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Add Next-Activity-Prediction to path\n",
        "na_root = project_root / \"Next-Activity-Prediction\"\n",
        "if str(na_root) not in sys.path:\n",
        "    sys.path.insert(0, str(na_root))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from bpic17_simplified import (\n",
        "    load_and_filter_bpic17,\n",
        "    add_end_tokens,\n",
        "    BPIC17SimplifiedDataGenerator,\n",
        "    BPIC17SimplifiedModel,\n",
        "    BPIC17SimplifiedPersistence\n",
        ")\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(f\"Training started: {datetime.now()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model will be saved to: d:\\Repos\\process-simulation-engine\\models\\bpic17_simplified\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "XES_PATH = os.path.join(project_root, \"Dataset\", \"BPI Challenge 2017.xes\")\n",
        "MODEL_DIR = os.path.join(project_root, \"models\", \"bpic17_simplified\")\n",
        "CHECKPOINT_DIR = os.path.join(MODEL_DIR, \"checkpoints\")\n",
        "\n",
        "# Training parameters\n",
        "MAX_HISTORY = 15\n",
        "MIN_SAMPLES = 10\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 128\n",
        "VALIDATION_SPLIT = 0.1\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# Model architecture\n",
        "LSTM_UNITS = 256\n",
        "HIDDEN_UNITS = 256\n",
        "\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Model will be saved to: {MODEL_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load and Preprocess Event Log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading and filtering BPIC 2017 event log...\n",
            "Log path: d:\\Repos\\process-simulation-engine\\Dataset\\BPI Challenge 2017.xes\n",
            "\n",
            "Filtered log statistics:\n",
            "  Events: 603,533\n",
            "  Cases: 31,509\n",
            "\n",
            "Lifecycle distribution:\n",
            "lifecycle:transition\n",
            "complete    475306\n",
            "start       128227\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(f\"Loading and filtering BPIC 2017 event log...\")\n",
        "print(f\"Log path: {XES_PATH}\")\n",
        "\n",
        "df_log = load_and_filter_bpic17(log_path=XES_PATH, lifecycle_filter=[\"start\", \"complete\"])\n",
        "\n",
        "print(f\"\\nFiltered log statistics:\")\n",
        "print(f\"  Events: {len(df_log):,}\")\n",
        "print(f\"  Cases: {df_log['case:concept:name'].nunique():,}\")\n",
        "print(f\"\\nLifecycle distribution:\")\n",
        "print(df_log['lifecycle:transition'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adding END tokens to traces...\n",
            "\n",
            "After adding END tokens:\n",
            "  Events: 635,042\n",
            "  END tokens: 31,509\n",
            "\n",
            "Activity distribution (top 10):\n",
            "concept:name\n",
            "W_Validate application      55292\n",
            "W_Complete application      49022\n",
            "O_Create Offer              42995\n",
            "O_Created                   42995\n",
            "O_Sent (mail and online)    39707\n",
            "A_Validating                38816\n",
            "W_Call after offers         31827\n",
            "A_Accepted                  31509\n",
            "END                         31509\n",
            "A_Create Application        31509\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Adding END tokens to traces...\")\n",
        "df_log = add_end_tokens(df_log, end_token=\"END\")\n",
        "\n",
        "print(f\"\\nAfter adding END tokens:\")\n",
        "print(f\"  Events: {len(df_log):,}\")\n",
        "print(f\"  END tokens: {(df_log['concept:name'] == 'END').sum():,}\")\n",
        "print(f\"\\nActivity distribution (top 10):\")\n",
        "print(df_log['concept:name'].value_counts().head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Generate Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating training data...\n",
            "\n",
            "Generated 603,529 training sequences\n",
            "Unique target activities: 25\n",
            "Unique target lifecycles: 2\n",
            "\n",
            "Target activity distribution (top 10):\n",
            "target_activity\n",
            "W_Validate application      55292\n",
            "W_Complete application      49022\n",
            "O_Created                   42995\n",
            "O_Create Offer              42995\n",
            "O_Sent (mail and online)    39707\n",
            "A_Validating                38816\n",
            "W_Call after offers         31827\n",
            "A_Accepted                  31509\n",
            "A_Concept                   31509\n",
            "END                         31509\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Target lifecycle distribution:\n",
            "target_lifecycle\n",
            "complete    475306\n",
            "start       128223\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Generating training data...\")\n",
        "generator = BPIC17SimplifiedDataGenerator(\n",
        "    df_log,\n",
        "    max_history=MAX_HISTORY,\n",
        "    min_samples=MIN_SAMPLES,\n",
        ")\n",
        "\n",
        "df_train = generator.generate()\n",
        "\n",
        "print(f\"\\nGenerated {len(df_train):,} training sequences\")\n",
        "print(f\"Unique target activities: {df_train['target_activity'].nunique()}\")\n",
        "print(f\"Unique target lifecycles: {df_train['target_lifecycle'].nunique()}\")\n",
        "\n",
        "print(f\"\\nTarget activity distribution (top 10):\")\n",
        "print(df_train['target_activity'].value_counts().head(10))\n",
        "\n",
        "print(f\"\\nTarget lifecycle distribution:\")\n",
        "print(df_train['target_lifecycle'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing model...\n",
            "\n",
            "Training model...\n",
            "  Epochs: 30\n",
            "  Batch size: 128\n",
            "  Validation split: 0.1\n",
            "Activity classes: 25, samples: 603529\n",
            "  Most common: 55292 samples, Least common: 76 samples\n",
            "Epoch 1/30\n",
            "\u001b[1m4244/4244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - activity_accuracy: 0.7468 - activity_loss: 0.7387 - lifecycle_accuracy: 0.8560 - lifecycle_loss: 0.2882 - loss: 0.8252\n",
            "Epoch 1: val_activity_accuracy improved from None to 0.86582, saving model to d:\\Repos\\process-simulation-engine\\models\\bpic17_simplified\\checkpoints\\best_model.keras\n",
            "\n",
            "Epoch 1: finished saving model to d:\\Repos\\process-simulation-engine\\models\\bpic17_simplified\\checkpoints\\best_model.keras\n",
            "\u001b[1m4244/4244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m796s\u001b[0m 185ms/step - activity_accuracy: 0.8231 - activity_loss: 0.4888 - lifecycle_accuracy: 0.8876 - lifecycle_loss: 0.2204 - loss: 0.5549 - val_activity_accuracy: 0.8658 - val_activity_loss: 0.3555 - val_lifecycle_accuracy: 0.9113 - val_lifecycle_loss: 0.1747 - val_loss: 0.4078 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m  12/4244\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:57\u001b[0m 184ms/step - activity_accuracy: 0.8661 - activity_loss: 0.3761 - lifecycle_accuracy: 0.9086 - lifecycle_loss: 0.1916 - loss: 0.4336"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Batch size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBATCH_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Validation split: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mVALIDATION_SPLIT\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[43mVALIDATION_SPLIT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Repos\\process-simulation-engine\\Next-Activity-Prediction\\bpic17_simplified\\model.py:345\u001b[39m, in \u001b[36mBPIC17SimplifiedModel.fit\u001b[39m\u001b[34m(self, df, epochs, batch_size, validation_split, checkpoint_path)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_path:\n\u001b[32m    335\u001b[39m     callbacks.append(\n\u001b[32m    336\u001b[39m         keras.callbacks.ModelCheckpoint(\n\u001b[32m    337\u001b[39m             checkpoint_path,\n\u001b[32m   (...)\u001b[39m\u001b[32m    342\u001b[39m         )\n\u001b[32m    343\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m history = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mactivity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_act\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlifecycle\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_lc\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Repos\\process-simulation-engine\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Repos\\process-simulation-engine\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:399\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    398\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Repos\\process-simulation-engine\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:241\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    239\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    240\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    243\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Repos\\process-simulation-engine\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Repos\\process-simulation-engine\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Repos\\process-simulation-engine\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Repos\\process-simulation-engine\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Repos\\process-simulation-engine\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Repos\\process-simulation-engine\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Repos\\process-simulation-engine\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Repos\\process-simulation-engine\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Repos\\process-simulation-engine\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "print(\"Initializing model...\")\n",
        "model = BPIC17SimplifiedModel(\n",
        "    max_seq_len=MAX_HISTORY,\n",
        "    lstm_units=LSTM_UNITS,\n",
        "    hidden_units=HIDDEN_UNITS,\n",
        ")\n",
        "\n",
        "checkpoint_path = os.path.join(CHECKPOINT_DIR, \"best_model.keras\")\n",
        "\n",
        "print(f\"\\nTraining model...\")\n",
        "print(f\"  Epochs: {EPOCHS}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Validation split: {VALIDATION_SPLIT}\")\n",
        "\n",
        "history = model.fit(\n",
        "    df_train,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=VALIDATION_SPLIT,\n",
        "    checkpoint_path=checkpoint_path,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training History\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m fig, axes = plt.subplots(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, figsize=(\u001b[32m15\u001b[39m, \u001b[32m10\u001b[39m))\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Activity accuracy\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m axes[\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m].plot(\u001b[43mhistory\u001b[49m.history[\u001b[33m'\u001b[39m\u001b[33mactivity_accuracy\u001b[39m\u001b[33m'\u001b[39m], label=\u001b[33m'\u001b[39m\u001b[33mTrain\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m axes[\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m].plot(history.history[\u001b[33m'\u001b[39m\u001b[33mval_activity_accuracy\u001b[39m\u001b[33m'\u001b[39m], label=\u001b[33m'\u001b[39m\u001b[33mValidation\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m axes[\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m].set_title(\u001b[33m'\u001b[39m\u001b[33mActivity Accuracy\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'history' is not defined"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x1000 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Activity accuracy\n",
        "axes[0, 0].plot(history.history['activity_accuracy'], label='Train')\n",
        "axes[0, 0].plot(history.history['val_activity_accuracy'], label='Validation')\n",
        "axes[0, 0].set_title('Activity Accuracy')\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Accuracy')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True)\n",
        "\n",
        "# Lifecycle accuracy\n",
        "axes[0, 1].plot(history.history['lifecycle_accuracy'], label='Train')\n",
        "axes[0, 1].plot(history.history['val_lifecycle_accuracy'], label='Validation')\n",
        "axes[0, 1].set_title('Lifecycle Accuracy')\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Accuracy')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True)\n",
        "\n",
        "# Activity loss\n",
        "axes[1, 0].plot(history.history['activity_loss'], label='Train')\n",
        "axes[1, 0].plot(history.history['val_activity_loss'], label='Validation')\n",
        "axes[1, 0].set_title('Activity Loss')\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Loss')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True)\n",
        "\n",
        "# Lifecycle loss\n",
        "axes[1, 1].plot(history.history['lifecycle_loss'], label='Train')\n",
        "axes[1, 1].plot(history.history['val_lifecycle_loss'], label='Validation')\n",
        "axes[1, 1].set_title('Lifecycle Loss')\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Loss')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nBest validation activity accuracy: {max(history.history['val_activity_accuracy']):.4f}\")\n",
        "print(f\"Best validation lifecycle accuracy: {max(history.history['val_lifecycle_accuracy']):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Save Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model...\n",
            "Saved model to d:\\Repos\\process-simulation-engine\\models\\bpic17_simplified\n",
            "  - model.keras\n",
            "  - encoder.pkl\n",
            "  - metadata.pkl\n",
            "\n",
            "Model saved successfully to: d:\\Repos\\process-simulation-engine\\models\\bpic17_simplified\n",
            "Training completed at: 2026-01-07 00:14:26.123186\n"
          ]
        }
      ],
      "source": [
        "print(\"Saving model...\")\n",
        "BPIC17SimplifiedPersistence.save(model, MODEL_DIR)\n",
        "\n",
        "print(f\"\\nModel saved successfully to: {MODEL_DIR}\")\n",
        "print(f\"Training completed at: {datetime.now()}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
