{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Suffix Prediction Model Training\n",
        "\n",
        "This notebook demonstrates how to train a sequence-to-sequence LSTM model for suffix prediction.\n",
        "\n",
        "The model:\n",
        "- Filters event logs to only \"start\" and \"complete\" lifecycle transitions\n",
        "- Learns to predict the entire remaining sequence (suffix) of activities for a case\n",
        "- Uses an encoder-decoder architecture to predict sequences instead of single activities\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import logging\n",
        "\n",
        "# Add project root to Python path\n",
        "project_root = Path.cwd().parent if Path.cwd().name == 'next_activity_prediction' else Path.cwd()\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "from next_activity_prediction import train_suffix_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration\n",
        "\n",
        "Configure the suffix prediction model architecture and training parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration:\n",
            "  Event log: ..\\eventlog\\eventlog.xes.gz\n",
            "  Model directory: models/suffix_prediction_lstm\n",
            "  Prefix length: 50\n",
            "  Suffix length: 30\n",
            "  Encoder LSTM units: 256\n",
            "  Decoder LSTM units: 256\n",
            "  Encoder layers: 2\n",
            "  Decoder layers: 2\n",
            "  Batch size: 64\n",
            "  Epochs: 1\n"
          ]
        }
      ],
      "source": [
        "# Path to your event log\n",
        "EVENT_LOG_PATH = r\"..\\eventlog\\eventlog.xes.gz\"  # Update this to your event log path\n",
        "\n",
        "# Model configuration\n",
        "config = {\n",
        "    \"event_log_path\": EVENT_LOG_PATH,\n",
        "    \"model_dir\": \"models/suffix_prediction_lstm\",  # Where to save the model\n",
        "    \n",
        "    # Sequence lengths\n",
        "    \"prefix_length\": 50,      # Maximum prefix length (input)\n",
        "    \"suffix_length\": 30,      # Maximum suffix length (output)\n",
        "    \"min_prefix_length\": 1,   # Minimum prefix length to consider\n",
        "    \n",
        "    # Model architecture\n",
        "    \"embedding_dim\": 128,     # Embedding dimension for activity tokens\n",
        "    \"encoder_lstm_units\": 256,    # Number of LSTM units in encoder\n",
        "    \"decoder_lstm_units\": 256,    # Number of LSTM units in decoder\n",
        "    \"encoder_lstm_layers\": 2,     # Number of encoder LSTM layers\n",
        "    \"decoder_lstm_layers\": 2,     # Number of decoder LSTM layers\n",
        "    \"dropout_rate\": 0.3,      # Dropout rate for regularization\n",
        "    \n",
        "    # Training parameters\n",
        "    \"batch_size\": 64,         # Batch size for training\n",
        "    \"learning_rate\": 0.001,   # Initial learning rate\n",
        "    \"epochs\": 1,             # Maximum number of training epochs\n",
        "    \"validation_split\": 0.2,  # Fraction of data for validation\n",
        "    \"early_stopping_patience\": 10,  # Early stopping patience\n",
        "    \n",
        "    # Data preprocessing\n",
        "    \"min_case_length\": 2,     # Minimum case length to include\n",
        "    \"max_case_length\": 200,   # Maximum case length (longer cases are truncated)\n",
        "    \"random_seed\": 42\n",
        "}\n",
        "\n",
        "print(\"Configuration:\")\n",
        "print(f\"  Event log: {config['event_log_path']}\")\n",
        "print(f\"  Model directory: {config['model_dir']}\")\n",
        "print(f\"  Prefix length: {config['prefix_length']}\")\n",
        "print(f\"  Suffix length: {config['suffix_length']}\")\n",
        "print(f\"  Encoder LSTM units: {config['encoder_lstm_units']}\")\n",
        "print(f\"  Decoder LSTM units: {config['decoder_lstm_units']}\")\n",
        "print(f\"  Encoder layers: {config['encoder_lstm_layers']}\")\n",
        "print(f\"  Decoder layers: {config['decoder_lstm_layers']}\")\n",
        "print(f\"  Batch size: {config['batch_size']}\")\n",
        "print(f\"  Epochs: {config['epochs']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Verify Event Log\n",
        "\n",
        "Check that the event log exists and has the required columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Event log loaded: 1202267 events, 31509 cases\n",
            "\n",
            "Columns: ['case:RequestedAmount', 'OfferedAmount', 'lifecycle:transition', 'concept:name', 'time:timestamp', 'OfferID', 'Accepted', 'case:concept:name', 'case:ApplicationType', 'EventOrigin', 'org:resource', 'Action', 'FirstWithdrawalAmount', 'EventID', 'CreditScore', 'MonthlyCost', 'NumberOfTerms', 'case:LoanGoal', 'Selected']\n",
            "\n",
            "Lifecycle transitions:\n",
            "lifecycle:transition\n",
            "complete     475306\n",
            "suspend      215402\n",
            "schedule     149104\n",
            "start        128227\n",
            "resume       127160\n",
            "ate_abort     85224\n",
            "withdraw      21844\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Start/Complete events: 603533 (50.2%)\n",
            "\n",
            "Unique activities: 26\n",
            "Sample activities: ['A_Create Application', 'A_Submitted', 'W_Handle leads', 'W_Complete application', 'A_Concept', 'A_Accepted', 'O_Create Offer', 'O_Created', 'O_Sent (mail and online)', 'W_Call after offers']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pm4py\n",
        "\n",
        "# Load and inspect event log\n",
        "event_log_path = config['event_log_path']\n",
        "if Path(event_log_path).exists():\n",
        "    log = pm4py.read_xes(event_log_path)\n",
        "    df = pm4py.convert_to_dataframe(log)\n",
        "    \n",
        "    print(f\"Event log loaded: {len(df)} events, {df['case:concept:name'].nunique()} cases\")\n",
        "    print(f\"\\nColumns: {list(df.columns)}\")\n",
        "    \n",
        "    # Check for lifecycle column\n",
        "    if 'lifecycle:transition' in df.columns:\n",
        "        lifecycle_counts = df['lifecycle:transition'].value_counts()\n",
        "        print(f\"\\nLifecycle transitions:\")\n",
        "        print(lifecycle_counts)\n",
        "        \n",
        "        start_complete = df[df['lifecycle:transition'].isin(['start', 'complete'])]\n",
        "        print(f\"\\nStart/Complete events: {len(start_complete)} ({len(start_complete)/len(df):.1%})\")\n",
        "    else:\n",
        "        print(\"\\nWarning: No 'lifecycle:transition' column found\")\n",
        "    \n",
        "    # Show sample activities\n",
        "    if 'concept:name' in df.columns:\n",
        "        activities = df['concept:name'].unique()\n",
        "        print(f\"\\nUnique activities: {len(activities)}\")\n",
        "        print(f\"Sample activities: {list(activities[:10])}\")\n",
        "else:\n",
        "    print(f\"Event log not found: {event_log_path}\")\n",
        "    print(\"Please update EVENT_LOG_PATH in the configuration cell above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train the Model\n",
        "\n",
        "Train the sequence-to-sequence LSTM model on the event log. This will:\n",
        "1. Load and preprocess the event log\n",
        "2. Filter to start/complete lifecycles\n",
        "3. Extract activity sequences and create prefix-suffix pairs\n",
        "4. Create training/validation splits\n",
        "5. Train the encoder-decoder model with early stopping\n",
        "6. Save the trained model and metadata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-09 15:01:37,217 - next_activity_prediction.suffix_trainer - INFO - Preprocessing event log...\n",
            "2026-01-09 15:01:37,218 - next_activity_prediction.suffix_data_preprocessing - INFO - Loading event log from ..\\eventlog\\eventlog.xes.gz\n",
            "2026-01-09 15:01:44,345 - next_activity_prediction.suffix_data_preprocessing - INFO - Loaded 1202267 events, 31509 cases\n",
            "2026-01-09 15:01:44,500 - next_activity_prediction.suffix_data_preprocessing - INFO - Filtered to start/complete lifecycles: 1,202,267 -> 603,533 (50.2%)\n",
            "2026-01-09 15:01:45,730 - next_activity_prediction.suffix_data_preprocessing - INFO - Extracted 31509 case sequences\n",
            "2026-01-09 15:01:45,735 - next_activity_prediction.suffix_data_preprocessing - INFO - Average sequence length: 20.2 (including END)\n",
            "2026-01-09 15:01:45,738 - next_activity_prediction.suffix_data_preprocessing - INFO - Min/Max sequence length: 9/68\n",
            "2026-01-09 15:01:45,797 - next_activity_prediction.suffix_data_preprocessing - INFO - Created vocabulary with 28 activities (including END)\n",
            "2026-01-09 15:01:45,798 - next_activity_prediction.suffix_data_preprocessing - INFO - END token index: 27\n",
            "2026-01-09 15:01:50,291 - next_activity_prediction.suffix_data_preprocessing - INFO - Prepared 603533 training samples for suffix prediction\n",
            "2026-01-09 15:01:50,292 - next_activity_prediction.suffix_data_preprocessing - INFO - Prefix shape: (603533, 50), Suffix shape: (603533, 30)\n",
            "2026-01-09 15:01:50,308 - next_activity_prediction.suffix_data_preprocessing - INFO - Samples with END token: 593208 (98.29%)\n",
            "2026-01-09 15:01:50,442 - next_activity_prediction.suffix_data_preprocessing - INFO - Train samples: 482826, Validation samples: 120707\n",
            "2026-01-09 15:01:50,493 - next_activity_prediction.suffix_trainer - INFO - Vocabulary size: 28\n",
            "2026-01-09 15:01:50,494 - next_activity_prediction.suffix_trainer - INFO - END token index: 27\n",
            "2026-01-09 15:01:50,494 - next_activity_prediction.suffix_trainer - INFO - Building model...\n",
            "d:\\Repos\\process-simulation-engine-1\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:100: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n",
            "2026-01-09 15:01:50,606 - next_activity_prediction.suffix_trainer - INFO - Model architecture:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-09 15:01:50,614 - next_activity_prediction.suffix_trainer - INFO - Model: \"suffix_prediction_lstm\"\n",
            "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
            "┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
            "│ prefix_input        │ (None, 50)        │          0 │ -                 │\n",
            "│ (InputLayer)        │                   │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ activity_embedding  │ (None, 50, 128)   │      3,584 │ prefix_input[0][… │\n",
            "│ (Embedding)         │                   │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ not_equal_1         │ (None, 50)        │          0 │ prefix_input[0][… │\n",
            "│ (NotEqual)          │                   │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ encoder_lstm_1      │ [(None, 50, 256), │    394,240 │ activity_embeddi… │\n",
            "│ (LSTM)              │ (None, 256),      │            │ not_equal_1[0][0] │\n",
            "│                     │ (None, 256)]      │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ encoder_lstm_2      │ [(None, 256),     │    525,312 │ encoder_lstm_1[0… │\n",
            "│ (LSTM)              │ (None, 256),      │            │ encoder_lstm_1[0… │\n",
            "│                     │ (None, 256)]      │            │ encoder_lstm_1[0… │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ repeat_vector       │ (None, 30, 256)   │          0 │ encoder_lstm_2[0… │\n",
            "│ (RepeatVector)      │                   │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ decoder_lstm_1      │ (None, 30, 256)   │    525,312 │ repeat_vector[0]… │\n",
            "│ (LSTM)              │                   │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ decoder_lstm_2      │ (None, 30, 256)   │    525,312 │ decoder_lstm_1[0… │\n",
            "│ (LSTM)              │                   │            │                   │\n",
            "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
            "│ time_distributed_o… │ (None, 30, 28)    │      7,196 │ decoder_lstm_2[0… │\n",
            "│ (TimeDistributed)   │                   │            │                   │\n",
            "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
            " Total params: 1,980,956 (7.56 MB)\n",
            " Trainable params: 1,980,956 (7.56 MB)\n",
            " Non-trainable params: 0 (0.00 B)\n",
            "\n",
            "2026-01-09 15:01:50,614 - next_activity_prediction.suffix_trainer - INFO - Training model...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7545/7545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 1.0386 - sparse_categorical_accuracy: 0.7139\n",
            "Epoch 1: val_loss improved from None to 0.88825, saving model to models\\suffix_prediction_lstm\\checkpoints\\best_model.keras\n",
            "\n",
            "Epoch 1: finished saving model to models\\suffix_prediction_lstm\\checkpoints\\best_model.keras\n",
            "\u001b[1m7545/7545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2111s\u001b[0m 279ms/step - loss: 0.9503 - sparse_categorical_accuracy: 0.7331 - val_loss: 0.8882 - val_sparse_categorical_accuracy: 0.7466\n",
            "Restoring model weights from the end of the best epoch: 1.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-09 15:37:02,152 - next_activity_prediction.suffix_trainer - INFO - Saved model to models\\suffix_prediction_lstm\\model.keras\n",
            "2026-01-09 15:37:02,154 - next_activity_prediction.suffix_trainer - INFO - Saved metadata to models\\suffix_prediction_lstm\\metadata.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training completed!\n"
          ]
        }
      ],
      "source": [
        "# Train the suffix prediction model\n",
        "model, metadata = train_suffix_model(**config)\n",
        "\n",
        "print(\"\\nTraining completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training Results\n",
        "\n",
        "The training history is stored in the metadata. Let's check the final metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Training Metrics:\n",
            "  Loss: 0.9503\n",
            "  Accuracy: 0.7331\n",
            "\n",
            "Final Validation Metrics:\n",
            "  Loss: 0.8882\n",
            "  Accuracy: 0.7466\n",
            "\n",
            "Epochs trained: 1\n"
          ]
        }
      ],
      "source": [
        "# Print training results from metadata\n",
        "if 'training_history' in metadata:\n",
        "    history = metadata['training_history']\n",
        "    print(\"Final Training Metrics:\")\n",
        "    print(f\"  Loss: {history.get('final_train_loss', 'N/A'):.4f}\" if isinstance(history.get('final_train_loss'), (int, float)) else f\"  Loss: {history.get('final_train_loss', 'N/A')}\")\n",
        "    print(f\"  Accuracy: {history.get('final_train_acc', 'N/A'):.4f}\" if isinstance(history.get('final_train_acc'), (int, float)) else f\"  Accuracy: {history.get('final_train_acc', 'N/A')}\")\n",
        "    print(f\"\\nFinal Validation Metrics:\")\n",
        "    print(f\"  Loss: {history.get('final_val_loss', 'N/A'):.4f}\" if isinstance(history.get('final_val_loss'), (int, float)) else f\"  Loss: {history.get('final_val_loss', 'N/A')}\")\n",
        "    print(f\"  Accuracy: {history.get('final_val_acc', 'N/A'):.4f}\" if isinstance(history.get('final_val_acc'), (int, float)) else f\"  Accuracy: {history.get('final_val_acc', 'N/A')}\")\n",
        "    print(f\"\\nEpochs trained: {history.get('epochs_trained', 'N/A')}\")\n",
        "else:\n",
        "    print(\"Training history not found in metadata\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Verify Model Files\n",
        "\n",
        "Check that the model and metadata were saved correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model directory: models\\suffix_prediction_lstm\n",
            "\n",
            "Files in model directory:\n",
            "  suffix_prediction_lstm\\checkpoints\\best_model.keras (22.73 MB)\n",
            "  suffix_prediction_lstm\\metadata.json (0.00 MB)\n",
            "  suffix_prediction_lstm\\model.keras (22.73 MB)\n",
            "\n",
            "✓ Metadata file exists: models\\suffix_prediction_lstm\\metadata.json\n",
            "\n",
            "Model metadata:\n",
            "  Model type: suffix_prediction_lstm\n",
            "  Vocabulary size: 28\n",
            "  Prefix length: 50\n",
            "  Suffix length: 30\n",
            "  END token index: 27\n"
          ]
        }
      ],
      "source": [
        "model_dir = Path(config['model_dir'])\n",
        "\n",
        "print(f\"Model directory: {model_dir}\")\n",
        "print(f\"\\nFiles in model directory:\")\n",
        "if model_dir.exists():\n",
        "    for file in sorted(model_dir.rglob('*')):\n",
        "        if file.is_file():\n",
        "            size = file.stat().st_size / (1024 * 1024)  # Size in MB\n",
        "            print(f\"  {file.relative_to(model_dir.parent)} ({size:.2f} MB)\")\n",
        "else:\n",
        "    print(f\"  Directory does not exist: {model_dir}\")\n",
        "\n",
        "# Check metadata\n",
        "metadata_file = model_dir / \"metadata.json\"\n",
        "if metadata_file.exists():\n",
        "    print(f\"\\n✓ Metadata file exists: {metadata_file}\")\n",
        "    print(f\"\\nModel metadata:\")\n",
        "    print(f\"  Model type: {metadata.get('model_type', 'N/A')}\")\n",
        "    print(f\"  Vocabulary size: {metadata.get('vocab_size', 'N/A')}\")\n",
        "    print(f\"  Prefix length: {metadata.get('prefix_length', 'N/A')}\")\n",
        "    print(f\"  Suffix length: {metadata.get('suffix_length', 'N/A')}\")\n",
        "    print(f\"  END token index: {metadata.get('end_token_idx', 'N/A')}\")\n",
        "else:\n",
        "    print(f\"\\n✗ Metadata file not found: {metadata_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Test the Predictor\n",
        "\n",
        "Test loading the model and making predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-09 15:58:28,920 - next_activity_prediction.suffix_predictor - INFO - Loading suffix prediction model from models/suffix_prediction_lstm...\n",
            "2026-01-09 15:58:29,144 - next_activity_prediction.suffix_predictor - INFO - Loaded suffix prediction model\n",
            "2026-01-09 15:58:29,145 - next_activity_prediction.suffix_predictor - INFO - Prefix length: 50, Suffix length: 30\n",
            "2026-01-09 15:58:29,145 - next_activity_prediction.suffix_predictor - INFO - Vocabulary size: 28\n",
            "2026-01-09 15:58:29,146 - next_activity_prediction.suffix_predictor - INFO - END token index: 27\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Suffix predictor loaded successfully\n",
            "\n",
            "Model configuration:\n",
            "  Prefix length: 50\n",
            "  Suffix length: 30\n",
            "  Vocabulary size: 28\n",
            "  END token index: 27\n",
            "\n",
            "Testing with prefix: ['A_Create Application', 'A_Submitted', 'A_Concept']\n",
            "\n",
            "Predicted next activity: A_Concept\n",
            "Is case ended: False\n",
            "\n",
            "Predicted suffix (first 10 activities): ['A_Concept', 'W_Complete application', 'A_Accepted', 'O_Create Offer', 'O_Created', 'O_Sent (mail and online)', 'W_Complete application', 'W_Call after offers', 'A_Complete', 'W_Validate application', 'A_Validating', 'O_Returned', '<PAD>', '<PAD>', '<PAD>']\n",
            "Current position in suffix: 1\n"
          ]
        }
      ],
      "source": [
        "from next_activity_prediction import LSTMSuffixPredictor\n",
        "\n",
        "# Load the predictor\n",
        "predictor = LSTMSuffixPredictor(model_path=config['model_dir'])\n",
        "\n",
        "print(\"✓ Suffix predictor loaded successfully\")\n",
        "print(f\"\\nModel configuration:\")\n",
        "print(f\"  Prefix length: {predictor.prefix_length}\")\n",
        "print(f\"  Suffix length: {predictor.suffix_length}\")\n",
        "print(f\"  Vocabulary size: {len(predictor.activity_to_idx)}\")\n",
        "print(f\"  END token index: {predictor.end_token_idx}\")\n",
        "\n",
        "# Test with a sample prefix\n",
        "from simulation.engine import CaseState\n",
        "\n",
        "# Create a sample case state with a prefix\n",
        "sample_prefix = [\"A_Create Application\", \"A_Submitted\", \"A_Concept\"]\n",
        "print(f\"\\nTesting with prefix: {sample_prefix}\")\n",
        "\n",
        "# Simulate a case state\n",
        "class MockCaseState:\n",
        "    def __init__(self, case_id, activity_history):\n",
        "        self.case_id = case_id\n",
        "        self.activity_history = activity_history\n",
        "\n",
        "case_state = MockCaseState(\"test_case_1\", sample_prefix)\n",
        "\n",
        "# Predict next activity (this will predict the entire suffix internally)\n",
        "next_activity, is_end = predictor.predict(case_state)\n",
        "print(f\"\\nPredicted next activity: {next_activity}\")\n",
        "print(f\"Is case ended: {is_end}\")\n",
        "\n",
        "# Check if suffix was cached\n",
        "if \"test_case_1\" in predictor.predicted_suffixes:\n",
        "    suffix = predictor.predicted_suffixes[\"test_case_1\"]\n",
        "    print(f\"\\nPredicted suffix (first 10 activities): {suffix[:15]}\")\n",
        "    \n",
        "    if predictor.suffix_positions.get(\"test_case_1\") is not None:\n",
        "        print(f\"Current position in suffix: {predictor.suffix_positions['test_case_1']}\")\n",
        "else:\n",
        "    print(\"\\nNote: Suffix not cached (case may have ended immediately)\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
