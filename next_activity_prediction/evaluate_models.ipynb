{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Evaluation Notebook\n",
        "\n",
        "This notebook evaluates the performance of both next activity prediction and suffix prediction models by:\n",
        "1. Loading the original filtered event log\n",
        "2. Generating traces using both models\n",
        "3. Comparing generated traces against the original log using various metrics:\n",
        "   - Activity distribution\n",
        "   - Case length distribution\n",
        "   - Activity sequence patterns\n",
        "   - END token prediction accuracy\n",
        "   - Trace similarity metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Repos\\process-simulation-engine-1\\.venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, \"object\"):\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "# Add project root to Python path\n",
        "project_root = Path.cwd().parent if Path.cwd().name == 'next_activity_prediction' else Path.cwd()\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "from next_activity_prediction import LSTMNextActivityPredictor, LSTMSuffixPredictor\n",
        "from next_activity_prediction.data_preprocessing import load_event_log, filter_lifecycles, extract_case_sequences\n",
        "\n",
        "# Set style for plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration\n",
        "\n",
        "Set paths to models and event log.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration:\n",
            "  Event log: ..\\eventlog\\eventlog.xes.gz\n",
            "  Next activity model: models/next_activity_lstm\n",
            "  Suffix model: models/suffix_prediction_lstm\n",
            "  Traces to generate: 1000\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "EVENT_LOG_PATH = r\"..\\eventlog\\eventlog.xes.gz\"  # Original event log\n",
        "NEXT_ACTIVITY_MODEL_PATH = \"models/next_activity_lstm\"  # Next activity model directory\n",
        "SUFFIX_MODEL_PATH = \"models/suffix_prediction_lstm\"  # Suffix prediction model directory\n",
        "\n",
        "# Evaluation parameters\n",
        "NUM_TRACES_TO_GENERATE = 1000  # Number of traces to generate for evaluation\n",
        "MAX_CASE_LENGTH = 200  # Maximum case length to prevent infinite loops\n",
        "\n",
        "print(\"Configuration:\")\n",
        "print(f\"  Event log: {EVENT_LOG_PATH}\")\n",
        "print(f\"  Next activity model: {NEXT_ACTIVITY_MODEL_PATH}\")\n",
        "print(f\"  Suffix model: {SUFFIX_MODEL_PATH}\")\n",
        "print(f\"  Traces to generate: {NUM_TRACES_TO_GENERATE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Original Event Log\n",
        "\n",
        "Load and filter the original event log to get the ground truth traces.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-09 16:04:00,076 - next_activity_prediction.data_preprocessing - INFO - Loading event log from ..\\eventlog\\eventlog.xes.gz\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading original event log...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Repos\\process-simulation-engine-1\\.venv\\Lib\\site-packages\\pm4py\\utils.py:987: UserWarning: In the current version, the import/export operation uses `rustxes` by default for importing/exporting files faster. Please uninstall `rustxes` to revert the behavior.\n",
            "  warnings.warn(\"In the current version, the import/export operation uses `rustxes` by default for importing/exporting files faster. Please uninstall `rustxes` to revert the behavior.\")\n",
            "2026-01-09 16:04:08,420 - next_activity_prediction.data_preprocessing - INFO - Loaded 1202267 events, 31509 cases\n",
            "2026-01-09 16:04:08,572 - next_activity_prediction.data_preprocessing - INFO - Filtered to start/complete lifecycles: 1,202,267 -> 603,533 (50.2%)\n",
            "2026-01-09 16:04:09,693 - next_activity_prediction.data_preprocessing - INFO - Extracted 31509 case sequences\n",
            "2026-01-09 16:04:09,696 - next_activity_prediction.data_preprocessing - INFO - Average sequence length: 20.2 (including END)\n",
            "2026-01-09 16:04:09,699 - next_activity_prediction.data_preprocessing - INFO - Min/Max sequence length: 9/68\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Original event log statistics:\n",
            "  Total cases: 31509\n",
            "  Average case length: 20.15\n",
            "  Min/Max case length: 9/68\n",
            "\n",
            "After removing END tokens:\n",
            "  Average case length: 19.15\n"
          ]
        }
      ],
      "source": [
        "# Load and filter original event log\n",
        "print(\"Loading original event log...\")\n",
        "df_original = load_event_log(EVENT_LOG_PATH)\n",
        "df_filtered = filter_lifecycles(df_original)\n",
        "\n",
        "# Extract case sequences\n",
        "original_sequences = extract_case_sequences(df_filtered, min_length=2, max_length=MAX_CASE_LENGTH)\n",
        "\n",
        "print(f\"\\nOriginal event log statistics:\")\n",
        "print(f\"  Total cases: {len(original_sequences)}\")\n",
        "print(f\"  Average case length: {np.mean([len(s) for s in original_sequences]):.2f}\")\n",
        "print(f\"  Min/Max case length: {min(len(s) for s in original_sequences)}/{max(len(s) for s in original_sequences)}\")\n",
        "\n",
        "# Remove END tokens for comparison (they're not in original sequences before we added them)\n",
        "original_sequences_clean = [seq[:-1] if seq[-1] == \"END\" else seq for seq in original_sequences]\n",
        "\n",
        "print(f\"\\nAfter removing END tokens:\")\n",
        "print(f\"  Average case length: {np.mean([len(s) for s in original_sequences_clean]):.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load Models\n",
        "\n",
        "Load both prediction models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading next activity predictor...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-09 16:04:10,022 - next_activity_prediction.predictor - INFO - Loaded LSTMNextActivityPredictor from models/next_activity_lstm\n",
            "2026-01-09 16:04:10,023 - next_activity_prediction.predictor - INFO - Vocabulary size: 28 (including END)\n",
            "2026-01-09 16:04:10,023 - next_activity_prediction.predictor - INFO - Sequence length: 50\n",
            "2026-01-09 16:04:10,024 - next_activity_prediction.predictor - INFO - END token index: 27\n",
            "2026-01-09 16:04:10,025 - next_activity_prediction.suffix_predictor - INFO - Loading suffix prediction model from models/suffix_prediction_lstm...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Next activity predictor loaded\n",
            "  Vocabulary size: 28\n",
            "  END token index: 27\n",
            "\n",
            "Loading suffix predictor...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-09 16:04:10,269 - next_activity_prediction.suffix_predictor - INFO - Loaded suffix prediction model\n",
            "2026-01-09 16:04:10,270 - next_activity_prediction.suffix_predictor - INFO - Prefix length: 50, Suffix length: 30\n",
            "2026-01-09 16:04:10,270 - next_activity_prediction.suffix_predictor - INFO - Vocabulary size: 28\n",
            "2026-01-09 16:04:10,270 - next_activity_prediction.suffix_predictor - INFO - END token index: 27\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Suffix predictor loaded\n",
            "  Vocabulary size: 28\n",
            "  Prefix length: 50\n",
            "  Suffix length: 30\n"
          ]
        }
      ],
      "source": [
        "# Load next activity predictor\n",
        "print(\"Loading next activity predictor...\")\n",
        "try:\n",
        "    next_activity_predictor = LSTMNextActivityPredictor(model_path=NEXT_ACTIVITY_MODEL_PATH)\n",
        "    print(f\"✓ Next activity predictor loaded\")\n",
        "    print(f\"  Vocabulary size: {len(next_activity_predictor.activity_to_idx)}\")\n",
        "    print(f\"  END token index: {next_activity_predictor.end_token_idx}\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Failed to load next activity predictor: {e}\")\n",
        "    next_activity_predictor = None\n",
        "\n",
        "# Load suffix predictor\n",
        "print(\"\\nLoading suffix predictor...\")\n",
        "try:\n",
        "    suffix_predictor = LSTMSuffixPredictor(model_path=SUFFIX_MODEL_PATH)\n",
        "    print(f\"✓ Suffix predictor loaded\")\n",
        "    print(f\"  Vocabulary size: {len(suffix_predictor.activity_to_idx)}\")\n",
        "    print(f\"  Prefix length: {suffix_predictor.prefix_length}\")\n",
        "    print(f\"  Suffix length: {suffix_predictor.suffix_length}\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Failed to load suffix predictor: {e}\")\n",
        "    suffix_predictor = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Generate Traces\n",
        "\n",
        "Generate traces using both models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating traces with next activity predictor...\n",
            "  Generated 100/1000 traces\n",
            "  Generated 200/1000 traces\n",
            "  Generated 300/1000 traces\n",
            "  Generated 400/1000 traces\n",
            "  Generated 500/1000 traces\n",
            "  Generated 600/1000 traces\n",
            "  Generated 700/1000 traces\n",
            "  Generated 800/1000 traces\n",
            "  Generated 900/1000 traces\n"
          ]
        }
      ],
      "source": [
        "class MockCaseState:\n",
        "    \"\"\"Mock case state for trace generation.\"\"\"\n",
        "    def __init__(self, case_id, activity_history):\n",
        "        self.case_id = case_id\n",
        "        self.activity_history = activity_history\n",
        "\n",
        "def generate_trace(predictor, case_id: str, max_length: int = MAX_CASE_LENGTH) -> List[str]:\n",
        "    \"\"\"\n",
        "    Generate a complete trace using a predictor.\n",
        "    \n",
        "    Args:\n",
        "        predictor: Next activity or suffix predictor\n",
        "        case_id: Case identifier\n",
        "        max_length: Maximum trace length to prevent infinite loops\n",
        "        \n",
        "    Returns:\n",
        "        List of activity names (trace)\n",
        "    \"\"\"\n",
        "    trace = []\n",
        "    case_state = MockCaseState(case_id, [])\n",
        "    \n",
        "    for step in range(max_length):\n",
        "        next_activity, is_end = predictor.predict(case_state)\n",
        "        \n",
        "        if is_end:\n",
        "            # Add the final activity and break\n",
        "            if next_activity not in [\"END\", \"FAILED\"]:\n",
        "                trace.append(next_activity)\n",
        "            break\n",
        "        \n",
        "        trace.append(next_activity)\n",
        "        case_state.activity_history = trace.copy()\n",
        "    \n",
        "    # Reset predictor state for this case\n",
        "    predictor.reset_case(case_id)\n",
        "    \n",
        "    return trace\n",
        "\n",
        "# Generate traces with next activity predictor\n",
        "print(\"Generating traces with next activity predictor...\")\n",
        "next_activity_traces = []\n",
        "if next_activity_predictor:\n",
        "    for i in range(NUM_TRACES_TO_GENERATE):\n",
        "        case_id = f\"next_activity_case_{i}\"\n",
        "        trace = generate_trace(next_activity_predictor, case_id, max_length=MAX_CASE_LENGTH)\n",
        "        next_activity_traces.append(trace)\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"  Generated {i + 1}/{NUM_TRACES_TO_GENERATE} traces\")\n",
        "    print(f\"✓ Generated {len(next_activity_traces)} traces\")\n",
        "else:\n",
        "    print(\"✗ Skipping (model not loaded)\")\n",
        "\n",
        "# Generate traces with suffix predictor\n",
        "print(\"\\nGenerating traces with suffix predictor...\")\n",
        "suffix_traces = []\n",
        "if suffix_predictor:\n",
        "    for i in range(NUM_TRACES_TO_GENERATE):\n",
        "        case_id = f\"suffix_case_{i}\"\n",
        "        trace = generate_trace(suffix_predictor, case_id, max_length=MAX_CASE_LENGTH)\n",
        "        suffix_traces.append(trace)\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"  Generated {i + 1}/{NUM_TRACES_TO_GENERATE} traces\")\n",
        "    print(f\"✓ Generated {len(suffix_traces)} traces\")\n",
        "else:\n",
        "    print(\"✗ Skipping (model not loaded)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Compare Case Length Distributions\n",
        "\n",
        "Compare the distribution of case lengths between original log and generated traces.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate case lengths\n",
        "original_lengths = [len(seq) for seq in original_sequences_clean[:NUM_TRACES_TO_GENERATE]]\n",
        "next_activity_lengths = [len(trace) for trace in next_activity_traces] if next_activity_traces else []\n",
        "suffix_lengths = [len(trace) for trace in suffix_traces] if suffix_traces else []\n",
        "\n",
        "# Create comparison plot\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Original\n",
        "axes[0].hist(original_lengths, bins=30, alpha=0.7, edgecolor='black')\n",
        "axes[0].set_title(f'Original Log\\n(n={len(original_lengths)}, μ={np.mean(original_lengths):.1f})')\n",
        "axes[0].set_xlabel('Case Length')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Next Activity\n",
        "if next_activity_lengths:\n",
        "    axes[1].hist(next_activity_lengths, bins=30, alpha=0.7, edgecolor='black', color='orange')\n",
        "    axes[1].set_title(f'Next Activity Model\\n(n={len(next_activity_lengths)}, μ={np.mean(next_activity_lengths):.1f})')\n",
        "    axes[1].set_xlabel('Case Length')\n",
        "    axes[1].set_ylabel('Frequency')\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "else:\n",
        "    axes[1].text(0.5, 0.5, 'Model not loaded', ha='center', va='center', transform=axes[1].transAxes)\n",
        "    axes[1].set_title('Next Activity Model')\n",
        "\n",
        "# Suffix\n",
        "if suffix_lengths:\n",
        "    axes[2].hist(suffix_lengths, bins=30, alpha=0.7, edgecolor='black', color='green')\n",
        "    axes[2].set_title(f'Suffix Model\\n(n={len(suffix_lengths)}, μ={np.mean(suffix_lengths):.1f})')\n",
        "    axes[2].set_xlabel('Case Length')\n",
        "    axes[2].set_ylabel('Frequency')\n",
        "    axes[2].grid(True, alpha=0.3)\n",
        "else:\n",
        "    axes[2].text(0.5, 0.5, 'Model not loaded', ha='center', va='center', transform=axes[2].transAxes)\n",
        "    axes[2].set_title('Suffix Model')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print statistics\n",
        "print(\"Case Length Statistics:\")\n",
        "print(f\"\\nOriginal Log:\")\n",
        "print(f\"  Mean: {np.mean(original_lengths):.2f}\")\n",
        "print(f\"  Median: {np.median(original_lengths):.2f}\")\n",
        "print(f\"  Std: {np.std(original_lengths):.2f}\")\n",
        "print(f\"  Min/Max: {min(original_lengths)}/{max(original_lengths)}\")\n",
        "\n",
        "if next_activity_lengths:\n",
        "    print(f\"\\nNext Activity Model:\")\n",
        "    print(f\"  Mean: {np.mean(next_activity_lengths):.2f}\")\n",
        "    print(f\"  Median: {np.median(next_activity_lengths):.2f}\")\n",
        "    print(f\"  Std: {np.std(next_activity_lengths):.2f}\")\n",
        "    print(f\"  Min/Max: {min(next_activity_lengths)}/{max(next_activity_lengths)}\")\n",
        "\n",
        "if suffix_lengths:\n",
        "    print(f\"\\nSuffix Model:\")\n",
        "    print(f\"  Mean: {np.mean(suffix_lengths):.2f}\")\n",
        "    print(f\"  Median: {np.median(suffix_lengths):.2f}\")\n",
        "    print(f\"  Std: {np.std(suffix_lengths):.2f}\")\n",
        "    print(f\"  Min/Max: {min(suffix_lengths)}/{max(suffix_lengths)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Compare Activity Distributions\n",
        "\n",
        "Compare the frequency of each activity in original log vs generated traces.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count activities\n",
        "def count_activities(traces: List[List[str]]) -> Counter:\n",
        "    \"\"\"Count all activities across all traces.\"\"\"\n",
        "    all_activities = []\n",
        "    for trace in traces:\n",
        "        all_activities.extend(trace)\n",
        "    return Counter(all_activities)\n",
        "\n",
        "original_activity_counts = count_activities(original_sequences_clean[:NUM_TRACES_TO_GENERATE])\n",
        "next_activity_counts = count_activities(next_activity_traces) if next_activity_traces else Counter()\n",
        "suffix_counts = count_activities(suffix_traces) if suffix_traces else Counter()\n",
        "\n",
        "# Get all unique activities\n",
        "all_activities = set(original_activity_counts.keys())\n",
        "if next_activity_traces:\n",
        "    all_activities.update(next_activity_counts.keys())\n",
        "if suffix_traces:\n",
        "    all_activities.update(suffix_counts.keys())\n",
        "all_activities = sorted(all_activities)\n",
        "\n",
        "# Normalize to percentages\n",
        "def normalize_counts(counter: Counter, total: int) -> Dict[str, float]:\n",
        "    \"\"\"Convert counts to percentages.\"\"\"\n",
        "    if total == 0:\n",
        "        return {}\n",
        "    return {act: (counter[act] / total) * 100 for act in all_activities}\n",
        "\n",
        "total_original = sum(original_activity_counts.values())\n",
        "total_next_activity = sum(next_activity_counts.values()) if next_activity_traces else 0\n",
        "total_suffix = sum(suffix_counts.values()) if suffix_traces else 0\n",
        "\n",
        "original_pct = normalize_counts(original_activity_counts, total_original)\n",
        "next_activity_pct = normalize_counts(next_activity_counts, total_next_activity) if next_activity_traces else {}\n",
        "suffix_pct = normalize_counts(suffix_counts, total_suffix) if suffix_traces else {}\n",
        "\n",
        "# Create comparison DataFrame\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Activity': all_activities,\n",
        "    'Original (%)': [original_pct.get(act, 0) for act in all_activities],\n",
        "    'Next Activity (%)': [next_activity_pct.get(act, 0) for act in all_activities] if next_activity_traces else [0] * len(all_activities),\n",
        "    'Suffix (%)': [suffix_pct.get(act, 0) for act in all_activities] if suffix_traces else [0] * len(all_activities),\n",
        "})\n",
        "\n",
        "# Sort by original frequency\n",
        "comparison_df = comparison_df.sort_values('Original (%)', ascending=False)\n",
        "\n",
        "# Plot top activities\n",
        "top_n = 20\n",
        "top_activities = comparison_df.head(top_n)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "x = np.arange(len(top_activities))\n",
        "width = 0.25\n",
        "\n",
        "ax.bar(x - width, top_activities['Original (%)'], width, label='Original', alpha=0.8)\n",
        "if next_activity_traces:\n",
        "    ax.bar(x, top_activities['Next Activity (%)'], width, label='Next Activity', alpha=0.8)\n",
        "if suffix_traces:\n",
        "    ax.bar(x + width, top_activities['Suffix (%)'], width, label='Suffix', alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('Activity')\n",
        "ax.set_ylabel('Percentage (%)')\n",
        "ax.set_title(f'Activity Distribution Comparison (Top {top_n} Activities)')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(top_activities['Activity'], rotation=45, ha='right')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print top activities\n",
        "print(f\"\\nTop {top_n} Activities by Frequency:\")\n",
        "print(comparison_df.head(top_n).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Sequence Pattern Analysis\n",
        "\n",
        "Compare common activity sequences (n-grams) between original and generated traces.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_ngrams(traces: List[List[str]], n: int = 2) -> Counter:\n",
        "    \"\"\"Extract n-grams from traces.\"\"\"\n",
        "    ngrams = []\n",
        "    for trace in traces:\n",
        "        for i in range(len(trace) - n + 1):\n",
        "            ngram = tuple(trace[i:i+n])\n",
        "            ngrams.append(ngram)\n",
        "    return Counter(ngrams)\n",
        "\n",
        "# Extract bigrams (2-grams)\n",
        "original_bigrams = extract_ngrams(original_sequences_clean[:NUM_TRACES_TO_GENERATE], n=2)\n",
        "next_activity_bigrams = extract_ngrams(next_activity_traces, n=2) if next_activity_traces else Counter()\n",
        "suffix_bigrams = extract_ngrams(suffix_traces, n=2) if suffix_traces else Counter()\n",
        "\n",
        "# Get top bigrams\n",
        "top_bigrams_original = original_bigrams.most_common(15)\n",
        "\n",
        "print(\"Top 15 Bigrams (Activity Pairs) in Original Log:\")\n",
        "for i, (bigram, count) in enumerate(top_bigrams_original, 1):\n",
        "    print(f\"  {i:2d}. {bigram[0]} -> {bigram[1]}: {count} occurrences\")\n",
        "\n",
        "if next_activity_traces:\n",
        "    print(\"\\nTop 15 Bigrams in Next Activity Model:\")\n",
        "    top_bigrams_next = next_activity_bigrams.most_common(15)\n",
        "    for i, (bigram, count) in enumerate(top_bigrams_next, 1):\n",
        "        print(f\"  {i:2d}. {bigram[0]} -> {bigram[1]}: {count} occurrences\")\n",
        "    \n",
        "    # Calculate overlap\n",
        "    original_bigram_set = set(original_bigrams.keys())\n",
        "    next_bigram_set = set(next_activity_bigrams.keys())\n",
        "    overlap = original_bigram_set.intersection(next_bigram_set)\n",
        "    overlap_pct = (len(overlap) / len(original_bigram_set)) * 100 if original_bigram_set else 0\n",
        "    print(f\"\\n  Bigram overlap: {len(overlap)}/{len(original_bigram_set)} ({overlap_pct:.1f}%)\")\n",
        "\n",
        "if suffix_traces:\n",
        "    print(\"\\nTop 15 Bigrams in Suffix Model:\")\n",
        "    top_bigrams_suffix = suffix_bigrams.most_common(15)\n",
        "    for i, (bigram, count) in enumerate(top_bigrams_suffix, 1):\n",
        "        print(f\"  {i:2d}. {bigram[0]} -> {bigram[1]}: {count} occurrences\")\n",
        "    \n",
        "    # Calculate overlap\n",
        "    original_bigram_set = set(original_bigrams.keys())\n",
        "    suffix_bigram_set = set(suffix_bigrams.keys())\n",
        "    overlap = original_bigram_set.intersection(suffix_bigram_set)\n",
        "    overlap_pct = (len(overlap) / len(original_bigram_set)) * 100 if original_bigram_set else 0\n",
        "    print(f\"\\n  Bigram overlap: {len(overlap)}/{len(original_bigram_set)} ({overlap_pct:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Trace Similarity Metrics\n",
        "\n",
        "Calculate similarity metrics between original and generated traces.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def jaccard_similarity(set1: set, set2: set) -> float:\n",
        "    \"\"\"Calculate Jaccard similarity between two sets.\"\"\"\n",
        "    intersection = len(set1.intersection(set2))\n",
        "    union = len(set1.union(set2))\n",
        "    return intersection / union if union > 0 else 0.0\n",
        "\n",
        "def trace_similarity(trace1: List[str], trace2: List[str]) -> float:\n",
        "    \"\"\"Calculate similarity between two traces (set-based Jaccard).\"\"\"\n",
        "    set1 = set(trace1)\n",
        "    set2 = set(trace2)\n",
        "    return jaccard_similarity(set1, set2)\n",
        "\n",
        "def sequence_similarity(trace1: List[str], trace2: List[str]) -> float:\n",
        "    \"\"\"Calculate sequence similarity (longest common subsequence ratio).\"\"\"\n",
        "    def lcs_length(s1, s2):\n",
        "        m, n = len(s1), len(s2)\n",
        "        dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "        for i in range(1, m + 1):\n",
        "            for j in range(1, n + 1):\n",
        "                if s1[i-1] == s2[j-1]:\n",
        "                    dp[i][j] = dp[i-1][j-1] + 1\n",
        "                else:\n",
        "                    dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n",
        "        return dp[m][n]\n",
        "    \n",
        "    lcs = lcs_length(trace1, trace2)\n",
        "    max_len = max(len(trace1), len(trace2))\n",
        "    return lcs / max_len if max_len > 0 else 0.0\n",
        "\n",
        "# Sample original traces for comparison\n",
        "sample_size = min(100, len(original_sequences_clean))\n",
        "sample_original = original_sequences_clean[:sample_size]\n",
        "\n",
        "# Calculate similarities for next activity model\n",
        "if next_activity_traces:\n",
        "    next_activity_similarities = []\n",
        "    next_activity_seq_similarities = []\n",
        "    \n",
        "    for i in range(min(sample_size, len(next_activity_traces))):\n",
        "        orig_trace = sample_original[i]\n",
        "        gen_trace = next_activity_traces[i]\n",
        "        \n",
        "        sim = trace_similarity(orig_trace, gen_trace)\n",
        "        seq_sim = sequence_similarity(orig_trace, gen_trace)\n",
        "        \n",
        "        next_activity_similarities.append(sim)\n",
        "        next_activity_seq_similarities.append(seq_sim)\n",
        "    \n",
        "    print(\"Next Activity Model Similarity Metrics:\")\n",
        "    print(f\"  Average Jaccard similarity: {np.mean(next_activity_similarities):.3f}\")\n",
        "    print(f\"  Average sequence similarity: {np.mean(next_activity_seq_similarities):.3f}\")\n",
        "\n",
        "# Calculate similarities for suffix model\n",
        "if suffix_traces:\n",
        "    suffix_similarities = []\n",
        "    suffix_seq_similarities = []\n",
        "    \n",
        "    for i in range(min(sample_size, len(suffix_traces))):\n",
        "        orig_trace = sample_original[i]\n",
        "        gen_trace = suffix_traces[i]\n",
        "        \n",
        "        sim = trace_similarity(orig_trace, gen_trace)\n",
        "        seq_sim = sequence_similarity(orig_trace, gen_trace)\n",
        "        \n",
        "        suffix_similarities.append(sim)\n",
        "        suffix_seq_similarities.append(seq_sim)\n",
        "    \n",
        "    print(\"\\nSuffix Model Similarity Metrics:\")\n",
        "    print(f\"  Average Jaccard similarity: {np.mean(suffix_similarities):.3f}\")\n",
        "    print(f\"  Average sequence similarity: {np.mean(suffix_seq_similarities):.3f}\")\n",
        "\n",
        "# Plot similarity distributions\n",
        "if (next_activity_traces or suffix_traces):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Jaccard similarity\n",
        "    if next_activity_traces:\n",
        "        axes[0].hist(next_activity_similarities, bins=20, alpha=0.6, label='Next Activity', color='orange')\n",
        "    if suffix_traces:\n",
        "        axes[0].hist(suffix_similarities, bins=20, alpha=0.6, label='Suffix', color='green')\n",
        "    axes[0].set_xlabel('Jaccard Similarity')\n",
        "    axes[0].set_ylabel('Frequency')\n",
        "    axes[0].set_title('Trace Set Similarity (Jaccard)')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Sequence similarity\n",
        "    if next_activity_traces:\n",
        "        axes[1].hist(next_activity_seq_similarities, bins=20, alpha=0.6, label='Next Activity', color='orange')\n",
        "    if suffix_traces:\n",
        "        axes[1].hist(suffix_seq_similarities, bins=20, alpha=0.6, label='Suffix', color='green')\n",
        "    axes[1].set_xlabel('Sequence Similarity (LCS Ratio)')\n",
        "    axes[1].set_ylabel('Frequency')\n",
        "    axes[1].set_title('Trace Sequence Similarity (LCS)')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Summary Statistics\n",
        "\n",
        "Generate a summary comparison table.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create summary statistics\n",
        "summary_data = {\n",
        "    'Metric': [\n",
        "        'Number of Traces',\n",
        "        'Mean Case Length',\n",
        "        'Median Case Length',\n",
        "        'Std Case Length',\n",
        "        'Unique Activities',\n",
        "        'Total Activity Count',\n",
        "    ],\n",
        "    'Original': [\n",
        "        len(original_sequences_clean[:NUM_TRACES_TO_GENERATE]),\n",
        "        f\"{np.mean(original_lengths):.2f}\",\n",
        "        f\"{np.median(original_lengths):.2f}\",\n",
        "        f\"{np.std(original_lengths):.2f}\",\n",
        "        len(original_activity_counts),\n",
        "        total_original,\n",
        "    ],\n",
        "}\n",
        "\n",
        "if next_activity_traces:\n",
        "    summary_data['Next Activity'] = [\n",
        "        len(next_activity_traces),\n",
        "        f\"{np.mean(next_activity_lengths):.2f}\",\n",
        "        f\"{np.median(next_activity_lengths):.2f}\",\n",
        "        f\"{np.std(next_activity_lengths):.2f}\",\n",
        "        len(next_activity_counts),\n",
        "        total_next_activity,\n",
        "    ]\n",
        "    \n",
        "    # Add similarity metrics if calculated\n",
        "    if 'next_activity_similarities' in locals():\n",
        "        summary_data['Metric'].extend([\n",
        "            'Avg Jaccard Similarity',\n",
        "            'Avg Sequence Similarity',\n",
        "        ])\n",
        "        summary_data['Original'].extend(['-', '-'])\n",
        "        summary_data['Next Activity'].extend([\n",
        "            f\"{np.mean(next_activity_similarities):.3f}\",\n",
        "            f\"{np.mean(next_activity_seq_similarities):.3f}\",\n",
        "        ])\n",
        "\n",
        "if suffix_traces:\n",
        "    if 'Next Activity' not in summary_data:\n",
        "        summary_data['Next Activity'] = ['-'] * len(summary_data['Metric'])\n",
        "    \n",
        "    summary_data['Suffix'] = [\n",
        "        len(suffix_traces),\n",
        "        f\"{np.mean(suffix_lengths):.2f}\",\n",
        "        f\"{np.median(suffix_lengths):.2f}\",\n",
        "        f\"{np.std(suffix_lengths):.2f}\",\n",
        "        len(suffix_counts),\n",
        "        total_suffix,\n",
        "    ]\n",
        "    \n",
        "    # Add similarity metrics if calculated\n",
        "    if 'suffix_similarities' in locals():\n",
        "        if 'Avg Jaccard Similarity' not in summary_data['Metric']:\n",
        "            summary_data['Metric'].extend([\n",
        "                'Avg Jaccard Similarity',\n",
        "                'Avg Sequence Similarity',\n",
        "            ])\n",
        "            summary_data['Original'].extend(['-', '-'])\n",
        "            if 'Next Activity' in summary_data:\n",
        "                summary_data['Next Activity'].extend(['-', '-'])\n",
        "        \n",
        "        summary_data['Suffix'].extend([\n",
        "            f\"{np.mean(suffix_similarities):.3f}\",\n",
        "            f\"{np.mean(suffix_seq_similarities):.3f}\",\n",
        "        ])\n",
        "    elif len(summary_data['Suffix']) < len(summary_data['Metric']):\n",
        "        summary_data['Suffix'].extend(['-'] * (len(summary_data['Metric']) - len(summary_data['Suffix'])))\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "print(summary_df.to_string(index=False))\n",
        "print(\"=\"*80)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
