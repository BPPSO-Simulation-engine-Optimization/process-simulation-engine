{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Process Simulation Engine - Demo\n",
        "\n",
        "This notebook demonstrates the simulation engine capabilities:\n",
        "- Running a simulation with several hundred cases\n",
        "- Displaying the generated event log\n",
        "- Computing basic metrics (case duration, activities, events per case)\n",
        "- Visualizing the process with DFG (Directly Follows Graph)\n",
        "- Comprehensive statistics analysis\n",
        "\n",
        "## 1. Setup and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path().resolve()\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Import simulation components\n",
        "from integration.config import SimulationConfig\n",
        "from integration.setup import setup_simulation\n",
        "from simulation.engine import DESEngine\n",
        "from simulation.log_exporter import LogExporter\n",
        "from resources import ResourceAllocator\n",
        "\n",
        "# Import pm4py for analysis\n",
        "try:\n",
        "    import pm4py\n",
        "    PM4PY_AVAILABLE = True\n",
        "except ImportError:\n",
        "    PM4PY_AVAILABLE = False\n",
        "    print(\"WARNING: pm4py not available. Install with: pip install pm4py\")\n",
        "\n",
        "# Configuration\n",
        "EVENT_LOG_PATH = \"eventlog/eventlog.xes.gz\"\n",
        "NUM_CASES = 500  # Simulate 500 cases for demo\n",
        "OUTPUT_DIR = \"integration/output\"\n",
        "\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Event log path: {EVENT_LOG_PATH}\")\n",
        "print(f\"Number of cases to simulate: {NUM_CASES}\")\n",
        "print(f\"PM4Py available: {PM4PY_AVAILABLE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Event Log and Setup Simulation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_event_log(path: str) -> pd.DataFrame:\n",
        "    \"\"\"Load event log from XES or CSV file.\"\"\"\n",
        "    if path.endswith('.xes') or path.endswith('.xes.gz'):\n",
        "        log = pm4py.read_xes(path)\n",
        "        df = pm4py.convert_to_dataframe(log)\n",
        "    elif path.endswith('.csv'):\n",
        "        df = pd.read_csv(path)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file format: {path}\")\n",
        "    \n",
        "    print(f\"Loaded event log: {len(df)} events, {df['case:concept:name'].nunique()} cases\")\n",
        "    return df\n",
        "\n",
        "# Load original event log\n",
        "print(f\"Loading event log from: {EVENT_LOG_PATH}\")\n",
        "df_original = load_event_log(EVENT_LOG_PATH)\n",
        "\n",
        "# Get start date from event log\n",
        "if 'time:timestamp' in df_original.columns:\n",
        "    start_date = pd.to_datetime(df_original['time:timestamp']).min().to_pydatetime()\n",
        "else:\n",
        "    start_date = datetime(2016, 1, 4, 8, 0)\n",
        "\n",
        "print(f\"Simulation start date: {start_date}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Run Simulation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create configuration (using advanced mode for better results)\n",
        "config = SimulationConfig.all_advanced(\n",
        "    event_log_path=EVENT_LOG_PATH,\n",
        "    num_cases=NUM_CASES,\n",
        ")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"SIMULATION CONFIGURATION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"  Processing time mode: {config.processing_time_mode}\")\n",
        "print(f\"  Case arrival mode: {config.case_arrival_mode}\")\n",
        "print(f\"  Case attribute mode: {config.case_attribute_mode}\")\n",
        "print(f\"  Number of cases: {config.num_cases}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create resource allocator\n",
        "print(\"\\nCreating resource allocator...\")\n",
        "allocator = ResourceAllocator(log_path=EVENT_LOG_PATH)\n",
        "print(\"Resource allocator created\")\n",
        "\n",
        "# Setup predictors\n",
        "print(\"\\nSetting up predictors...\")\n",
        "arrivals, next_act_pred, proc_pred, attr_pred = setup_simulation(\n",
        "    config,\n",
        "    df=df_original,\n",
        "    start_date=start_date,\n",
        ")\n",
        "print(f\"Generated {len(arrivals)} arrival timestamps\")\n",
        "\n",
        "# Adjust start_time to be the earliest of simulation start date or first arrival\n",
        "engine_start_time = start_date\n",
        "if arrivals and len(arrivals) > 0:\n",
        "    if arrivals[0] < start_date:\n",
        "        engine_start_time = arrivals[0]\n",
        "        print(f\"Adjusting simulation start time to first arrival: {engine_start_time}\")\n",
        "\n",
        "# Create and run engine\n",
        "print(\"\\nInitializing DESEngine...\")\n",
        "engine = DESEngine(\n",
        "    resource_allocator=allocator,\n",
        "    arrival_timestamps=arrivals,\n",
        "    next_activity_predictor=next_act_pred,\n",
        "    processing_time_predictor=proc_pred,\n",
        "    case_attribute_predictor=attr_pred,\n",
        "    start_time=engine_start_time,\n",
        ")\n",
        "\n",
        "print(\"\\nRunning simulation...\")\n",
        "events = engine.run(num_cases=len(arrivals))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SIMULATION RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"  Cases started: {engine.stats['cases_started']}\")\n",
        "print(f\"  Cases completed: {engine.stats['cases_completed']}\")\n",
        "print(f\"  Events generated: {len(events)}\")\n",
        "print(f\"  Outside hours: {engine.stats['outside_hours_count']}\")\n",
        "print(f\"  No eligible: {engine.stats['no_eligible_failures']}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Export and Display Event Log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export to CSV and XES\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "csv_path = os.path.join(OUTPUT_DIR, \"simulated_log.csv\")\n",
        "xes_path = os.path.join(OUTPUT_DIR, \"simulated_log.xes\")\n",
        "\n",
        "LogExporter.to_csv(events, csv_path)\n",
        "print(f\"Exported CSV to: {csv_path}\")\n",
        "\n",
        "if PM4PY_AVAILABLE:\n",
        "    try:\n",
        "        LogExporter.to_xes(events, xes_path)\n",
        "        print(f\"Exported XES to: {xes_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not export XES: {e}\")\n",
        "\n",
        "# Convert to DataFrame for analysis\n",
        "df_simulated = pd.DataFrame(events)\n",
        "\n",
        "# Display first few rows\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SAMPLE EVENT LOG (First 10 rows)\")\n",
        "print(\"=\" * 60)\n",
        "display_cols = ['case:concept:name', 'concept:name', 'time:timestamp', 'org:resource']\n",
        "available_cols = [col for col in display_cols if col in df_simulated.columns]\n",
        "print(df_simulated[available_cols].head(10).to_string())\n",
        "\n",
        "print(f\"\\nTotal columns in event log: {len(df_simulated.columns)}\")\n",
        "print(f\"Column names: {list(df_simulated.columns)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Basic Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure timestamp column is datetime\n",
        "if 'time:timestamp' in df_simulated.columns:\n",
        "    df_simulated['time:timestamp'] = pd.to_datetime(df_simulated['time:timestamp'])\n",
        "\n",
        "# Case duration (in seconds)\n",
        "case_durations = df_simulated.groupby('case:concept:name')['time:timestamp'].agg(\n",
        "    lambda x: (x.max() - x.min()).total_seconds()\n",
        ")\n",
        "\n",
        "# Events per case\n",
        "events_per_case = df_simulated.groupby('case:concept:name').size()\n",
        "\n",
        "# Activities per case (unique activities)\n",
        "activities_per_case = df_simulated.groupby('case:concept:name')['concept:name'].nunique()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"BASIC METRICS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nCase Duration (seconds):\")\n",
        "print(f\"  Mean: {case_durations.mean():.2f}\")\n",
        "print(f\"  Std:  {case_durations.std():.2f}\")\n",
        "print(f\"  Min:  {case_durations.min():.2f}\")\n",
        "print(f\"  Max:  {case_durations.max():.2f}\")\n",
        "\n",
        "print(f\"\\nEvents per Case:\")\n",
        "print(f\"  Mean: {events_per_case.mean():.2f}\")\n",
        "print(f\"  Std:  {events_per_case.std():.2f}\")\n",
        "print(f\"  Min:  {events_per_case.min()}\")\n",
        "print(f\"  Max:  {events_per_case.max()}\")\n",
        "\n",
        "print(f\"\\nActivities per Case (unique):\")\n",
        "print(f\"  Mean: {activities_per_case.mean():.2f}\")\n",
        "print(f\"  Std:  {activities_per_case.std():.2f}\")\n",
        "print(f\"  Min:  {activities_per_case.min()}\")\n",
        "print(f\"  Max:  {activities_per_case.max()}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Visualizations\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Case duration distribution\n",
        "axes[0].hist(case_durations / 3600, bins=30, edgecolor='black', alpha=0.7)\n",
        "axes[0].set_xlabel('Case Duration (hours)')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].set_title('Case Duration Distribution')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Events per case distribution\n",
        "axes[1].hist(events_per_case, bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
        "axes[1].set_xlabel('Number of Events')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "axes[1].set_title('Events per Case Distribution')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Activities per case distribution\n",
        "axes[2].hist(activities_per_case, bins=30, edgecolor='black', alpha=0.7, color='green')\n",
        "axes[2].set_xlabel('Number of Unique Activities')\n",
        "axes[2].set_ylabel('Frequency')\n",
        "axes[2].set_title('Activities per Case Distribution')\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. DFG Visualization (Directly Follows Graph)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if PM4PY_AVAILABLE:\n",
        "    # Discover DFG (frequency-based)\n",
        "    dfg_freq, start_activities, end_activities = pm4py.discover_dfg(df_simulated)\n",
        "    \n",
        "    # Get activity counts for visualization\n",
        "    activity_counts = df_simulated['concept:name'].value_counts().to_dict()\n",
        "    \n",
        "    # Visualize frequency DFG\n",
        "    print(\"Creating Frequency DFG...\")\n",
        "    gviz_freq = pm4py.visualize_dfg(\n",
        "        dfg_freq,\n",
        "        start_activities=start_activities,\n",
        "        end_activities=end_activities,\n",
        "        activities_count=activity_counts,\n",
        "        variant=\"frequency\"\n",
        "    )\n",
        "    \n",
        "    # Save and display\n",
        "    freq_output = os.path.join(OUTPUT_DIR, \"dfg_frequency.png\")\n",
        "    pm4py.save_vis_dfg(gviz_freq, freq_output)\n",
        "    print(f\"Frequency DFG saved to: {freq_output}\")\n",
        "    \n",
        "    # Discover performance DFG (with timing information)\n",
        "    print(\"\\nCreating Performance DFG (with timing)...\")\n",
        "    \n",
        "    # Calculate service times (time between events)\n",
        "    df_sorted = df_simulated.sort_values(['case:concept:name', 'time:timestamp'])\n",
        "    df_sorted['time_diff'] = df_sorted.groupby('case:concept:name')['time:timestamp'].diff()\n",
        "    \n",
        "    # Calculate average service time per activity\n",
        "    serv_time = {}\n",
        "    for activity in df_sorted['concept:name'].unique():\n",
        "        activity_events = df_sorted[df_sorted['concept:name'] == activity]\n",
        "        # Use time_diff where available, otherwise estimate from case duration\n",
        "        times = activity_events['time_diff'].dropna()\n",
        "        if len(times) > 0:\n",
        "            serv_time[activity] = times.mean().total_seconds() / 3600  # Convert to hours\n",
        "    \n",
        "    # Discover performance DFG\n",
        "    dfg_perf, start_activities, end_activities = pm4py.discover_dfg(df_simulated)\n",
        "    \n",
        "    # Visualize performance DFG\n",
        "    gviz_perf = pm4py.visualize_dfg(\n",
        "        dfg_perf,\n",
        "        start_activities=start_activities,\n",
        "        end_activities=end_activities,\n",
        "        serv_time=serv_time,\n",
        "        variant=\"performance\"\n",
        "    )\n",
        "    \n",
        "    # Save and display\n",
        "    perf_output = os.path.join(OUTPUT_DIR, \"dfg_performance.png\")\n",
        "    pm4py.save_vis_dfg(gviz_perf, perf_output)\n",
        "    print(f\"Performance DFG saved to: {perf_output}\")\n",
        "    \n",
        "    # Display the graphs\n",
        "    from IPython.display import Image, display\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"FREQUENCY DFG\")\n",
        "    print(\"=\" * 60)\n",
        "    display(Image(freq_output))\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PERFORMANCE DFG (with timing)\")\n",
        "    print(\"=\" * 60)\n",
        "    display(Image(perf_output))\n",
        "else:\n",
        "    print(\"PM4Py not available. Skipping DFG visualization.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate comprehensive statistics\n",
        "stats = {}\n",
        "\n",
        "# Basic counts\n",
        "stats['number_of_cases'] = df_simulated['case:concept:name'].nunique()\n",
        "stats['number_of_events'] = len(df_simulated)\n",
        "\n",
        "# Process variants\n",
        "if PM4PY_AVAILABLE:\n",
        "    variants = pm4py.get_variants(df_simulated)\n",
        "    stats['number_of_process_variants'] = len(variants)\n",
        "else:\n",
        "    # Manual variant calculation\n",
        "    variants_dict = {}\n",
        "    for case_id, case_df in df_simulated.groupby('case:concept:name'):\n",
        "        variant = tuple(case_df.sort_values('time:timestamp')['concept:name'].tolist())\n",
        "        variants_dict[variant] = variants_dict.get(variant, 0) + 1\n",
        "    stats['number_of_process_variants'] = len(variants_dict)\n",
        "\n",
        "# Case and event labels\n",
        "stats['number_of_case_labels'] = df_simulated['case:concept:name'].nunique()\n",
        "stats['number_of_event_labels'] = df_simulated['concept:name'].nunique()\n",
        "\n",
        "# Case length (number of events per case)\n",
        "case_lengths = df_simulated.groupby('case:concept:name').size()\n",
        "stats['mean_case_length'] = case_lengths.mean()\n",
        "stats['std_case_length'] = case_lengths.std()\n",
        "\n",
        "# Case duration statistics\n",
        "case_durations_seconds = case_durations\n",
        "case_durations_days = case_durations_seconds / (24 * 3600)\n",
        "case_durations_minutes = case_durations_seconds / 60\n",
        "\n",
        "stats['mean_case_duration_days'] = case_durations_days.mean()\n",
        "stats['std_case_duration_days'] = case_durations_days.std()\n",
        "stats['mean_case_duration_minutes'] = case_durations_minutes.mean()\n",
        "stats['std_case_duration_minutes'] = case_durations_minutes.std()\n",
        "stats['mean_case_duration_seconds'] = case_durations_seconds.mean()\n",
        "stats['std_case_duration_seconds'] = case_durations_seconds.std()\n",
        "\n",
        "# Categorical event attributes\n",
        "categorical_attrs = []\n",
        "for col in df_simulated.columns:\n",
        "    if col not in ['case:concept:name', 'concept:name', 'time:timestamp']:\n",
        "        # Check if column is categorical (object type with limited unique values)\n",
        "        if df_simulated[col].dtype == 'object':\n",
        "            unique_ratio = df_simulated[col].nunique() / len(df_simulated)\n",
        "            if unique_ratio < 0.5:  # Less than 50% unique values suggests categorical\n",
        "                categorical_attrs.append(col)\n",
        "        elif df_simulated[col].dtype in ['int64', 'int32']:\n",
        "            # Integer columns with few unique values might be categorical\n",
        "            if df_simulated[col].nunique() < 20:\n",
        "                categorical_attrs.append(col)\n",
        "\n",
        "stats['number_of_categorical_event_attributes'] = len(categorical_attrs)\n",
        "\n",
        "# Display statistics\n",
        "print(\"=\" * 60)\n",
        "print(\"COMPREHENSIVE STATISTICS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nBasic Counts:\")\n",
        "print(f\"  Number of cases: {stats['number_of_cases']:,}\")\n",
        "print(f\"  Number of events: {stats['number_of_events']:,}\")\n",
        "print(f\"  Number of process variants: {stats['number_of_process_variants']:,}\")\n",
        "print(f\"  Number of case labels: {stats['number_of_case_labels']:,}\")\n",
        "print(f\"  Number of event labels (activities): {stats['number_of_event_labels']}\")\n",
        "\n",
        "print(f\"\\nCase Length Statistics:\")\n",
        "print(f\"  Mean case length (events per case): {stats['mean_case_length']:.2f}\")\n",
        "print(f\"  Std case length: {stats['std_case_length']:.2f}\")\n",
        "\n",
        "print(f\"\\nCase Duration Statistics:\")\n",
        "print(f\"  Mean case duration: {stats['mean_case_duration_days']:.2f} days ({stats['mean_case_duration_minutes']:.2f} minutes, {stats['mean_case_duration_seconds']:.2f} seconds)\")\n",
        "print(f\"  Std case duration: {stats['std_case_duration_days']:.2f} days ({stats['std_case_duration_minutes']:.2f} minutes, {stats['std_case_duration_seconds']:.2f} seconds)\")\n",
        "\n",
        "print(f\"\\nEvent Attributes:\")\n",
        "print(f\"  Number of categorical event attributes: {stats['number_of_categorical_event_attributes']}\")\n",
        "if categorical_attrs:\n",
        "    print(f\"  Categorical attributes: {', '.join(categorical_attrs[:10])}\")\n",
        "    if len(categorical_attrs) > 10:\n",
        "        print(f\"  ... and {len(categorical_attrs) - 10} more\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create summary DataFrame\n",
        "summary_df = pd.DataFrame([\n",
        "    ['Number of cases', f\"{stats['number_of_cases']:,}\"],\n",
        "    ['Number of events', f\"{stats['number_of_events']:,}\"],\n",
        "    ['Number of process variants', f\"{stats['number_of_process_variants']:,}\"],\n",
        "    ['Number of case labels', f\"{stats['number_of_case_labels']:,}\"],\n",
        "    ['Number of event labels (activities)', f\"{stats['number_of_event_labels']}\"],\n",
        "    ['Mean case length', f\"{stats['mean_case_length']:.2f}\"],\n",
        "    ['Std case length', f\"{stats['std_case_length']:.2f}\"],\n",
        "    ['Mean case duration (days)', f\"{stats['mean_case_duration_days']:.2f}\"],\n",
        "    ['Std case duration (days)', f\"{stats['std_case_duration_days']:.2f}\"],\n",
        "    ['Mean case duration (minutes)', f\"{stats['mean_case_duration_minutes']:.2f}\"],\n",
        "    ['Std case duration (minutes)', f\"{stats['std_case_duration_minutes']:.2f}\"],\n",
        "    ['Mean case duration (seconds)', f\"{stats['mean_case_duration_seconds']:.2f}\"],\n",
        "    ['Std case duration (seconds)', f\"{stats['std_case_duration_seconds']:.2f}\"],\n",
        "    ['Number of categorical event attributes', f\"{stats['number_of_categorical_event_attributes']}\"],\n",
        "], columns=['Metric', 'Value'])\n",
        "\n",
        "print(\"\\nSummary Table:\")\n",
        "display(summary_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Additional Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Activity frequency\n",
        "activity_freq = df_simulated['concept:name'].value_counts()\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Top activities\n",
        "top_n = 15\n",
        "activity_freq.head(top_n).plot(kind='barh', ax=axes[0, 0], color='steelblue')\n",
        "axes[0, 0].set_xlabel('Frequency')\n",
        "axes[0, 0].set_title(f'Top {top_n} Most Frequent Activities')\n",
        "axes[0, 0].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Case duration distribution (detailed)\n",
        "axes[0, 1].hist(case_durations_days, bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
        "axes[0, 1].set_xlabel('Case Duration (days)')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "axes[0, 1].set_title('Case Duration Distribution (Days)')\n",
        "axes[0, 1].axvline(stats['mean_case_duration_days'], color='red', linestyle='--', label=f\"Mean: {stats['mean_case_duration_days']:.2f}\")\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Events over time\n",
        "df_simulated_sorted = df_simulated.sort_values('time:timestamp')\n",
        "df_simulated_sorted['cumulative_events'] = range(1, len(df_simulated_sorted) + 1)\n",
        "df_simulated_sorted['cumulative_cases'] = df_simulated_sorted.groupby('case:concept:name').ngroup() + 1\n",
        "df_simulated_sorted['cumulative_cases'] = df_simulated_sorted['cumulative_cases'].cummax()\n",
        "\n",
        "axes[1, 0].plot(df_simulated_sorted['time:timestamp'], df_simulated_sorted['cumulative_events'], label='Cumulative Events', linewidth=2)\n",
        "axes[1, 0].set_xlabel('Time')\n",
        "axes[1, 0].set_ylabel('Cumulative Count')\n",
        "axes[1, 0].set_title('Cumulative Events Over Time')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Case length vs duration scatter\n",
        "case_stats = pd.DataFrame({\n",
        "    'length': case_lengths,\n",
        "    'duration_days': case_durations_days\n",
        "})\n",
        "\n",
        "axes[1, 1].scatter(case_stats['length'], case_stats['duration_days'], alpha=0.5, s=20)\n",
        "axes[1, 1].set_xlabel('Case Length (number of events)')\n",
        "axes[1, 1].set_ylabel('Case Duration (days)')\n",
        "axes[1, 1].set_title('Case Length vs Duration')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, 'comprehensive_analysis.png'), dpi=150, bbox_inches='tight')\n",
        "print(f\"Comprehensive analysis plot saved to: {os.path.join(OUTPUT_DIR, 'comprehensive_analysis.png')}\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
